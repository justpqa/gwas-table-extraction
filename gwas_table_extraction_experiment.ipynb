{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e006c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justpqa/advpai/venv/lib/python3.10/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n",
      "/Users/justpqa/advpai/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from rich.tree import Tree\n",
    "# from rich import print as rprint\n",
    "import io\n",
    "from typing import List, Union, Tuple, Dict\n",
    "from collections.abc import Iterable\n",
    "from tqdm import tqdm\n",
    "# import pdfplumber\n",
    "# import fitz \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "# import xmltodict\n",
    "import re\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "from difflib import SequenceMatcher\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.document import DocumentStream\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, BitsAndBytesConfig, LogitsProcessor, LogitsProcessorList\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd6002",
   "metadata": {},
   "source": [
    "Try to look at the pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd7240",
   "metadata": {},
   "source": [
    "Try to look at the website of the paper instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc6bc82",
   "metadata": {},
   "source": [
    "Try to use Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870cbbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to know the number of col of a table to make sure we try the right orientation with docling\n",
    "def extract_tables_num_col_lst_from_pmc(pmcid):\n",
    "    url = f\"https://www.ncbi.nlm.nih.gov/research/bionlp/RESTful/pmcoa.cgi/BioC_json/{pmcid}/unicode\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    tables_num_col_lst = []\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for d in data:\n",
    "            doc = d[\"documents\"]\n",
    "            for p in doc:\n",
    "                passage = p[\"passages\"]\n",
    "                for item in passage:\n",
    "                    if item.get(\"infons\", \"\").get(\"type\", \"\").lower() == \"table\" and \"text\" in item:\n",
    "                        table_str = item[\"text\"]\n",
    "                        num_col = 0\n",
    "                        for row in table_str.split(\"\\t \\t\"):\n",
    "                            row_lst = row.split(\"\\t\")\n",
    "                            num_col = max(num_col, len(row_lst))\n",
    "                        tables_num_col_lst.append(num_col)\n",
    "        print(f\"Successfully retrieve number of columns\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve number of columns: {response.status_code}\")\n",
    "        \n",
    "    return tables_num_col_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cell(val):\n",
    "    tag_pattern = r'\\s[a-z]$'\n",
    "    if isinstance(val, str):\n",
    "        return re.sub(tag_pattern, '', val)\n",
    "    return val\n",
    "\n",
    "def clean_headers(df):\n",
    "    tag_pattern = r'\\s[a-z]$'\n",
    "    new_cols = []\n",
    "    seen = {}\n",
    "    for col in df.columns:\n",
    "        if pd.isna(col):\n",
    "            new_cols.append(\"\")\n",
    "        else:\n",
    "            # 1. Apply the regex to the name string\n",
    "            clean_name = re.sub(tag_pattern, '', str(col))\n",
    "            # 2. Handle duplicates (e.g., if 'Price a' and 'Price b' both become 'Price')\n",
    "            if clean_name in seen:\n",
    "                seen[clean_name] += 1\n",
    "                clean_name = f\"{clean_name}_{seen[clean_name]}\"\n",
    "            else:\n",
    "                seen[clean_name] = 0\n",
    "            new_cols.append(clean_name)\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "def extract_tables_lst_from_pdf_and_num_col(file_name, tables_num_col_lst):\n",
    "    reader = PdfReader(file_name)\n",
    "    options = PdfPipelineOptions()\n",
    "    options.table_structure_options.mode = TableFormerMode.ACCURATE\n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(pipeline_options=options)\n",
    "        }\n",
    "    )\n",
    "    df_lst = []\n",
    "    row_pattern = r\"\\b(?:rs|s)\\d+\\S*\"\n",
    "\n",
    "    page_num = 1\n",
    "    while len(df_lst) < len(tables_num_col_lst) and page_num <= len(reader.pages):\n",
    "        for angle in [0, 90]: # Try normal, then try rotated\n",
    "            writer = PdfWriter()\n",
    "            page = reader.pages[page_num - 1]\n",
    "            \n",
    "            if angle != 0:\n",
    "                page.rotate(angle)\n",
    "            \n",
    "            writer.add_page(page)\n",
    "            \n",
    "            # Convert just this one page\n",
    "            pdf_buffer = io.BytesIO()\n",
    "            writer.write(pdf_buffer)\n",
    "            pdf_buffer.seek(0)\n",
    "            \n",
    "            doc_stream = DocumentStream(name=f\"page_{page_num}.pdf\", stream=pdf_buffer)\n",
    "            result = converter.convert(doc_stream)\n",
    "            \n",
    "            # Check if this rotation produced valid table rows\n",
    "            temp_dfs = []\n",
    "            for table in result.document.tables:\n",
    "                df = table.export_to_dataframe()\n",
    "                # check if table is empty\n",
    "                if (not df.empty):\n",
    "                    # Case 1: continue from previous table\n",
    "                    if len(df_lst) > 0 and df.shape[1] == df_lst[-1].shape[1]:\n",
    "                        # extra filters for tables that are snp related, we need to remove rows that do not have snp id\n",
    "                        # often are separation between sections\n",
    "                        for col in df.columns:\n",
    "                            # first modify \"\" -> nan\n",
    "                            df[col] = df[col].replace(r'^\\s*$', np.nan, regex=True).ffill()\n",
    "                        df[\"valid_row\"] = df.apply(lambda x: any(re.search(row_pattern, str(c)) for c in x), axis=1)\n",
    "                        df = df[df[\"valid_row\"]].drop(\"valid_row\", axis=1).reset_index().drop(\"index\", axis = 1)\n",
    "                        # some cell have the tag the end (often include a space and a small letter)\n",
    "                        df = df.map(clean_cell) \n",
    "                        df = clean_headers(df) \n",
    "                        if df_lst[-1].columns.equals(df.columns):\n",
    "                            df_lst[-1] = pd.concat([df_lst[-1], df], ignore_index = True)\n",
    "                        elif df.shape[1] == tables_num_col_lst[len(df_lst) + len(temp_dfs)]:\n",
    "                            # fail that test => add to temp since this is a new table\n",
    "                            temp_dfs.append(df)\n",
    "                    # Case 2: new table\n",
    "                    elif (len(df_lst) + len(temp_dfs)) < len(tables_num_col_lst) and df.shape[1] == tables_num_col_lst[len(df_lst) + len(temp_dfs)]: \n",
    "                        # extra filters for tables that are snp related, we need to remove rows that do not have snp id\n",
    "                        # often are separation between sections\n",
    "                        for col in df.columns:\n",
    "                            # first modify \"\" -> nan\n",
    "                            df[col] = df[col].replace(r'^\\s*$', np.nan, regex=True).ffill()\n",
    "                        df[\"valid_row\"] = df.apply(lambda x: any(re.search(row_pattern, str(c)) for c in x), axis=1)\n",
    "                        df = df[df[\"valid_row\"]].drop(\"valid_row\", axis=1).reset_index().drop(\"index\", axis = 1)\n",
    "                        # some cell have the tag the end (often include a space and a small letter)\n",
    "                        df = df.map(clean_cell) \n",
    "                        df = clean_headers(df)             \n",
    "                        temp_dfs.append(df)\n",
    "            if temp_dfs:\n",
    "                df_lst.extend(temp_dfs)\n",
    "                break\n",
    "            \n",
    "        page_num += 1\n",
    "\n",
    "    return df_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_lst_from_paper(pmcid, file_name, table_inx_to_extract=[]):\n",
    "    tables_num_col_lst = extract_tables_num_col_lst_from_pmc(pmcid)\n",
    "    if len(table_inx_to_extract) > 0:\n",
    "        tables_num_col_lst = [tables_num_col_lst[i] for i in table_inx_to_extract]\n",
    "    df_lst = extract_tables_lst_from_pdf_and_num_col(file_name, tables_num_col_lst)\n",
    "    return df_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6513d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcid = \"PMC10497850\"\n",
    "file_name = \"papers/ACEL-22-e13938.pdf\"\n",
    "df_lst = extract_tables_lst_from_paper(pmcid, file_name)\n",
    "for i in [3, 4]:\n",
    "    df_lst[i-1].to_csv(f\"tables/{file_name.split('/')[-1].replace('.pdf', '')}_table_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcid = \"PMC10115645\"\n",
    "file_name = \"papers/41591_2023_Article_2268.pdf\"  # Can be a local path or a URL\n",
    "df_lst = extract_tables_lst_from_paper(pmcid, file_name)\n",
    "for i in [1, 2]:\n",
    "    df_lst[i-1].to_csv(f\"tables/{file_name.split('/')[-1].replace('.pdf', '')}_table_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c76427",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcid = \"PMC9622429\"\n",
    "file_name = \"papers/nihms-1797266.pdf\"  # Can be a local path or a URL\n",
    "df_lst = extract_tables_lst_from_paper(pmcid, file_name)  \n",
    "for i in [3, 5, 6, 7, 8]:\n",
    "    df_lst[i-1].to_csv(f\"tables/{file_name.split('/')[-1].replace('.pdf', '')}_table_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcid = \"PMC10615750\"\n",
    "file_name = \"papers/Recent paper on AD GWAS (1).pdf\"  # Can be a local path or a URL\n",
    "df_lst = extract_tables_lst_from_paper(pmcid, file_name)  \n",
    "for i in [1, 2]:\n",
    "    df_lst[i-1].to_csv(f\"tables/{file_name.split('/')[-1].replace('.pdf', '')}_table_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ae61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcid = \"PMC6677735\"\n",
    "file_name = \"papers/s42003-019-0537-9.pdf\"  # Can be a local path or a URL\n",
    "df_lst = extract_tables_lst_from_paper(pmcid, file_name)  \n",
    "for i in [1]:\n",
    "    df_lst[i-1].to_csv(f\"tables/{file_name.split('/')[-1].replace('.pdf', '')}_table_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b843b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcid = \"PMC10286470\"\n",
    "file_name = \"papers/s13024-023-00633-4.pdf\"  # Can be a local path or a URL\n",
    "df_lst = extract_tables_lst_from_paper(pmcid, file_name)  \n",
    "for i in [2, 3]:\n",
    "    df_lst[i-1].to_csv(f\"tables/{file_name.split('/')[-1].replace('.pdf', '')}_table_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bce5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmcid = \"PMC9945061\"\n",
    "# file_name = \"PMID36809323_table_3.pdf\"\n",
    "# df_lst = extract_tables_lst_from_paper(pmcid, file_name)  \n",
    "# for i in [3]:\n",
    "#     df_lst[i-3].to_csv(f\"tables/{file_name.split('/')[-1].replace('.pdf', '')}_table_{i}.csv\", index=False)\n",
    "# problem in PMC api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c135bb",
   "metadata": {},
   "source": [
    "Try to map columns to reference columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try to map the columns with the actual col in advp\n",
    "# referencing_cols = pd.read_csv(\"Rules for harmonizing ADVP papers - Main cols.csv\")\n",
    "# referencing_cols[\"column_with_context\"] = referencing_cols.apply(lambda x: x[\"column\"] if pd.isna(x[\"description\"]) else x[\"column\"] + \": \" + x[\"description\"], axis = 1)\n",
    "# # referencing_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf842b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: before working in the main cell for mapping columns, write inference code here + setting up models here\n",
    "# def create_embeddings_from_model(sentences, model, tokenizer):\n",
    "#     input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "#     # get token embeddings\n",
    "#     with torch.no_grad():\n",
    "#         output = model(**input)\n",
    "#     token_embeddings = output[0]\n",
    "\n",
    "#     # extract mask and mean pooling for sentence embeddings\n",
    "#     input_mask_expanded = input['attention_mask'].unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "#     sentence_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "#     # final normalization\n",
    "#     sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "#     return sentence_embeddings\n",
    "\n",
    "# # setting up models\n",
    "# embeddings_model_name = \"NeuML/pubmedbert-base-embeddings\"\n",
    "# embeddings_model_tokenizer = AutoTokenizer.from_pretrained(embeddings_model_name)\n",
    "# embeddings_model = AutoModel.from_pretrained(embeddings_model_name)\n",
    "# embeddings_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4de235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SingleTokenBiasProcessor(LogitsProcessor):\n",
    "#     def __init__(self, token_ids, bias_value):\n",
    "#         self.token_ids = token_ids\n",
    "#         self.bias_value = bias_value\n",
    "\n",
    "#     def __call__(self, input_ids, scores):\n",
    "#         # Create a mask for allowed tokens\n",
    "#         mask = torch.full_like(scores, -float(\"inf\"))\n",
    "#         for tid in self.token_ids:\n",
    "#             mask[:, tid] = self.bias_value\n",
    "#         return scores + mask\n",
    "\n",
    "# def reranking_with_llm(col, candidates, llm_model, llm_model_tokenizer):\n",
    "#     \"\"\"\n",
    "#     LLM acts as a re-ranker to pick the best match from a list of candidates.\n",
    "#     \"\"\"\n",
    "#     # Format the candidates as a numbered list for the LLM\n",
    "\n",
    "#     prompt = f\"\"\"Task: Map clinical table headers to GWAS standard ontology, return a single number for the best choice\n",
    "\n",
    "# Header: \"p-value: 0.001, 5e-8, 0.43\"\n",
    "# Candidates: \n",
    "#     1. P-value: The statistical significance of the association. Keywords: P, P-value, P_adj, FDR. Examples: 5.0E-08, 0.0012, 1.2 x 10^-5, 0.05.\n",
    "#     2. Effect Size: The magnitude and direction of the association. Keywords: Beta, OR, HR, Estimate. Examples: Beta=0.25, OR=1.45, HR=1.12, Log(OR)=0.37.\n",
    "#     3. SNP: Variant identifier, or snp idenifier, or chr:pos. Keywords: chr:position, chr:pos, Variant, rsID, RS number, MarkerName, rs. Examples: rs12345, 20:45269867, 19:45411941:T:C, chr19:45411941, rs429358 (APOE ε4).\n",
    "# Best Match: 1\n",
    "\n",
    "# Header: \"rs_number: rs123, rs456, rs789\"\n",
    "# Candidates: \n",
    "#     1. Chr: Genomic chromosome identifier. Keywords: CHR, Chrom, Chromosome. Examples: 1, 19, X, chr19, chrX.\n",
    "#     2. Position: Genomic coordinate location. Keywords: BP, POS, Base Pair, start, end. Examples: 45411941, 10240500:10248600 (range), build 37.\n",
    "#     3. SNP: Variant identifier, or snp idenifier, or chr:pos. Keywords: chr:position, chr:pos, Variant, rsID, RS number, MarkerName, rs. Examples: rs12345, 20:45269867, 19:45411941:T:C, chr19:45411941, rs429358 (APOE ε4).\n",
    "# Best Match: 2\n",
    "\n",
    "# Header: \"{col}\"\n",
    "# Candidates: \n",
    "#     - {candidates[0]}\n",
    "#     - {candidates[1]}\n",
    "#     - {candidates[2]}\n",
    "# Best Match: \"\"\"\n",
    "\n",
    "#     allowed_indices = [str(i+1) for i in range(len(candidates))]\n",
    "#     allowed_token_ids = [llm_model_tokenizer.encode(idx, add_special_tokens=False)[0] for idx in allowed_indices]\n",
    "    \n",
    "#     # logit bias to limit tokens that can be output\n",
    "#     bias_processor = SingleTokenBiasProcessor(allowed_token_ids, 100.0)\n",
    "#     logits_processor = LogitsProcessorList([bias_processor])\n",
    "\n",
    "#     # 4. Generate exactly ONE token\n",
    "#     inputs = llm_model_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         output = llm_model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=1,      # Force exactly one token\n",
    "#             logits_processor=logits_processor, # Force it to be one of our numbers\n",
    "#             pad_token_id=llm_model_tokenizer.eos_token_id,\n",
    "#             do_sample=False        # Greedy decoding for consistency\n",
    "#         )\n",
    "\n",
    "#     # 5. Extract and Convert to Integer\n",
    "#     new_token = output[0][-1]\n",
    "#     predicted_text = llm_model_tokenizer.decode(new_token).strip()\n",
    "    \n",
    "#     try:\n",
    "#         idx = int(predicted_text) - 1 # Convert back to 0-based list index\n",
    "#         return candidates[idx]\n",
    "#     except (ValueError, IndexError):\n",
    "#         return col\n",
    "\n",
    "# llm_model_name = \"stanford-crfm/BioMedLM\"\n",
    "# llm_model_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "# llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     llm_model_name,\n",
    "#     torch_dtype=torch.bfloat16\n",
    "# ).to(device)\n",
    "# llm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f2831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try to first convert any abbreviation, then we match column with right semantic\n",
    "# gwas_abbreviation_dict = {\n",
    "#     \"CHR\": \"Chromosome number\",\n",
    "#     \"BP\": \"Base-pair position\",\n",
    "#     \"POS\": \"Position\",\n",
    "#     \"SNP\": \"Single nucleotide polymorphism identifier\",\n",
    "#     \"RS\": \"Reference Single nucleotide polymorphism\",\n",
    "#     \"VAR\": \"Variant\",\n",
    "#     \"ID\": \"identifier\",\n",
    "#     \"A1\": \"Effect allele / tested allele\",\n",
    "#     \"A2\": \"Other allele / non-effect allele\",\n",
    "#     \"REF\": \"Reference allele (genome reference)\",\n",
    "#     \"ALT\": \"Alternate allele\",\n",
    "#     \"EA\": \"Effect Allele\",\n",
    "#     \"NEA\": \"Non-Effect Allele\",\n",
    "#     \"RA\": \"Risk Allele\",\n",
    "#     \"OA\": \"Other Allele\",\n",
    "#     \"AF\": \"Allele Frequency (general term)\",\n",
    "#     \"RAF\": \"Risk Allele Frequency\",\n",
    "#     \"EAF\": \"Effect Allele Frequency\",\n",
    "#     \"MAF\": \"Minor Allele Frequency\",\n",
    "#     \"BETA\": \"Effect size (regression coefficient)\",\n",
    "#     \"OR\": \"Odds Ratio\",\n",
    "#     \"SE\": \"Standard Error of effect estimate\",\n",
    "#     \"Z\": \"Z-score statistic\",\n",
    "#     \"T\": \"T-statistic\",\n",
    "#     \"CI\": \"Confidence Interval\",\n",
    "#     \"P\": \"P-value\",\n",
    "#     \"PVAL\": \"P-value\",\n",
    "#     \"LOGP\": \"Negative log10 P-value\",\n",
    "#     \"Q\": \"Heterogeneity statistic (meta-analysis)\",\n",
    "#     \"I2\": \"I-squared heterogeneity metric\",\n",
    "#     \"HWE\": \"Hardy-Weinberg Equilibrium test statistic\",\n",
    "#     \"INFO\": \"Imputation quality score\",\n",
    "#     \"R2\": \"Imputation accuracy metric\",\n",
    "#     \"CALLRATE\": \"Genotype call rate\",\n",
    "#     \"MISSING\": \"Missing genotype rate\",\n",
    "#     \"N\": \"Total sample size\",\n",
    "#     \"N_CASES\": \"Number of cases (for binary traits)\",\n",
    "#     \"N_CONTROLS\": \"Number of controls (for binary traits)\",\n",
    "#     \"EUR\": \"European ancestry\",\n",
    "#     \"AFR\": \"African ancestry\",\n",
    "#     \"ASN\": \"Asian ancestry\",\n",
    "#     \"AMR\": \"Admixed American ancestry\",\n",
    "#     \"SAS\": \"South Asian ancestry\",\n",
    "#     \"EAS\": \"East Asian ancestry\",\n",
    "#     \"LD\": \"Linkage Disequilibrium\",\n",
    "#     \"DPRIME\": \"LD D’ value\",\n",
    "#     \"CADD\": \"CADD score (functional impact)\",\n",
    "#     \"EQTL\": \"Expression quantitative trait locus\",\n",
    "#     \"PQTL\": \"Protein QTL\",\n",
    "#     \"GWGAS\": \"Gene-wide association study\",\n",
    "#     \"PRS\": \"Polygenic Risk Score\",\n",
    "#     \"PGS\": \"Polygenic Score\",\n",
    "#     \"QC\": \"Quality Control\",\n",
    "#     \"MA\": \"Meta-analysis\",\n",
    "#     \"HLA\": \"Human Leukocyte Antigen region\",\n",
    "#     \"HR\": \"Hazard ratio\",\n",
    "#     \"HET\": \"Heterogeneity test\",\n",
    "#     \"APOE4\": \"APOE ε4\",\n",
    "#     \"APOE*4\": \"APOE ε4\",\n",
    "#     \"#\": \"Number of\",\n",
    "#     \"frq\": \"Frequency\",\n",
    "#     'β': \"Effect\",\n",
    "#     \"nsnps\": \"Number of Variants\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df00f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_col(col):\n",
    "#     \"\"\"\n",
    "#     Clean a column by replacing any possible abbreviation with their actual meaning for better semantic matching\n",
    "#     \"\"\"\n",
    "#     new_col = col\n",
    "#     for abb in gwas_abbreviation_dict:\n",
    "#         if re.search(fr\"[^a-zA-Z]{abb.lower()}[^a-zA-Z]\", new_col.lower()):\n",
    "#             new_col = re.sub(fr\"([^a-zA-Z]){abb.lower()}([^a-zA-Z])\", fr\"\\1{gwas_abbreviation_dict[abb]}\\2\", new_col.lower())\n",
    "#         elif re.search(fr\"^{abb.lower()}[^a-zA-Z]\", new_col.lower()):\n",
    "#             new_col = re.sub(fr\"^{abb.lower()}([^a-zA-Z])\", fr\"{gwas_abbreviation_dict[abb]}\\1\", new_col.lower())\n",
    "#         elif re.search(fr\"[^a-zA-Z]{abb.lower()}$\", new_col.lower()):\n",
    "#             new_col = re.sub(fr\"([^a-zA-Z]){abb.lower()}$\", fr\"\\1{gwas_abbreviation_dict[abb]}\", new_col.lower())\n",
    "#         elif re.search(fr\"^{abb.lower()}$\", new_col.lower()):\n",
    "#             new_col = re.sub(fr\"{abb.lower()}\", gwas_abbreviation_dict[abb], new_col.lower())\n",
    "#     # new_col = new_col.replace(\".\", \" \")\n",
    "#     return new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c45269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_col_prompt(col, example_values, num_example_values = 5):\n",
    "#     \"\"\"\n",
    "#     Based on the column title and some possible values of that columns, try to make a prompt\n",
    "#     \"\"\"\n",
    "#     col_prompt = f\"{col}: \"\n",
    "#     for i in range(min(num_example_values, len(example_values))):\n",
    "#         col_prompt += f\"{example_values[i]}, \"\n",
    "#     return col_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a589c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def match_single_col_to_ref_col(col, ref_col_lst, ref_col_embeddings, embeddings_model, embeddings_model_tokenizer):\n",
    "#     \"\"\"\n",
    "#     match a single column to reference col given column, the list of referencing col and their embeddings\n",
    "#     \"\"\"\n",
    "#     # calculate column embedding\n",
    "#     # col_embeddings = embeddings_model.encode(col, normalize_embeddings=True)\n",
    "#     # multi_index_pattern = r\".+\\..+\"\n",
    "#     # if re.search(multi_index_pattern, col):\n",
    "#     #     col = col.replace(\".\", \" \")\n",
    "#     #     # sub_col_lst = col.split(\".\")\n",
    "#     #     # sub_col_embeddings = create_embeddings_from_model(sub_col_lst, embeddings_model, embeddings_model_tokenizer)\n",
    "#     #     # col_embeddings = torch.mean(sub_col_embeddings, dim = 0)\n",
    "#     #     col = col.replace(\".\", \" \")\n",
    "#     #     col_embeddings = create_embeddings_from_model(col, embeddings_model, embeddings_model_tokenizer)\n",
    "#     # else:\n",
    "#     #     col_embeddings = create_embeddings_from_model(col, embeddings_model, embeddings_model_tokenizer)\n",
    "#     col_embeddings = create_embeddings_from_model(col, embeddings_model, embeddings_model_tokenizer)\n",
    "#     col_embeddings = col_embeddings.reshape(-1, 1)\n",
    "\n",
    "#     # calculate similarity score\n",
    "#     scores = torch.matmul(ref_col_embeddings, col_embeddings).reshape(-1)\n",
    "\n",
    "#     # sort similairty score\n",
    "#     top_k_indices = torch.argsort(scores, descending=True)\n",
    "\n",
    "#     # verify if we even got good enough similarity\n",
    "#     best_inx = top_k_indices[0].item()\n",
    "#     best_score = scores[best_inx].item()\n",
    "#     # second_best_inx = top_k_indices[1].item()\n",
    "#     # second_best_score = scores[second_best_inx].item()\n",
    "#     # need a threshold for score or else, just return col\n",
    "#     # if best_score < 0.4: \n",
    "#     #     return (col, 1)\n",
    "    \n",
    "#     # # now do rerank\n",
    "#     # candidates = [ref_col_lst[inx] for inx in top_k_indices if scores[inx] >= 0.4]\n",
    "#     # candidates_scores = [scores[inx] for inx in top_k_indices if scores[inx] >= 0.4]\n",
    "#     # best_ref_col, best_ref_col_scores = reranking_from_model(col, candidates, candidates_scores)\n",
    "#     # return (best_ref_col, best_ref_col_scores)\n",
    "\n",
    "#     if best_score >= 0.4:\n",
    "#         return (ref_col_lst[best_inx], best_score)\n",
    "#     return (col, 1)\n",
    "\n",
    "# def match_many_col_to_ref_col(df, ref_col_df, embeddings_model, embeddings_model_tokenizer):\n",
    "#     \"\"\"\n",
    "#     Given a list of column and a dataframe (could be dict later on if that fits better),\n",
    "#     try to match each column to the best fitted reference col, \n",
    "#     return a dict of ref col : list of (col, cleaned col prompt, score)\n",
    "#     \"\"\"\n",
    "#     # prepare the embeddings for reference col since we reuse them\n",
    "#     ref_col_lst = ref_col_df[\"column\"].to_list()\n",
    "#     ref_col_context_lst = ref_col_df[\"column_with_context\"].to_list()\n",
    "#     ref_col_embeddings = create_embeddings_from_model(ref_col_context_lst, embeddings_model, embeddings_model_tokenizer)\n",
    "\n",
    "#     # conduct matching\n",
    "#     multi_index_pattern = r\"^.+\\..+$\" # need multi index pattern for handling multi index\n",
    "#     ref_col_to_col_lst = {}\n",
    "#     for col in df.columns:\n",
    "\n",
    "#         # extract values needed for prompt\n",
    "#         cleaned_col = clean_col(col)\n",
    "#         example_values = df[col].unique().tolist()\n",
    "#         # prompt: {col}: example, need to delete all : first\n",
    "\n",
    "#         if re.search(multi_index_pattern, cleaned_col.strip()):\n",
    "#             # try to assess each part and see if which one have highest score\n",
    "#             best_ref_col, best_score = None, 0\n",
    "#             best_cleaned_sub_col_prompt = None\n",
    "#             for sub_col in cleaned_col.split(\".\"):\n",
    "\n",
    "#                 # make column prompt for each sub col\n",
    "#                 cleaned_sub_col_prompt = make_col_prompt(sub_col, example_values)\n",
    "                \n",
    "#                 # matching and compare\n",
    "#                 ref_col, score = match_single_col_to_ref_col(cleaned_sub_col_prompt, ref_col_lst, ref_col_embeddings, embeddings_model, embeddings_model_tokenizer)\n",
    "#                 if score > best_score and ref_col != cleaned_sub_col_prompt:\n",
    "#                     best_ref_col = ref_col\n",
    "#                     best_score = score\n",
    "#                     best_cleaned_sub_col_prompt = cleaned_sub_col_prompt\n",
    "            \n",
    "#             # if we have a best one vs not\n",
    "#             if best_ref_col is not None:\n",
    "#                 if best_ref_col not in ref_col_to_col_lst:\n",
    "#                     ref_col_to_col_lst[best_ref_col] = []\n",
    "#                 ref_col_to_col_lst[best_ref_col].append((col, best_cleaned_sub_col_prompt, score))\n",
    "#             else:\n",
    "#                 if col not in ref_col_to_col_lst:\n",
    "#                     ref_col_to_col_lst[col] = []\n",
    "#                 ref_col_to_col_lst[col].append((col, best_cleaned_sub_col_prompt, 1))\n",
    "#         else:\n",
    "#             # match a single col with best fit referencing col and return a dict\n",
    "#             # make the col prompt\n",
    "#             # extra steps to remove .\n",
    "#             cleaned_col = cleaned_col.replace(\".\", \"\")\n",
    "#             cleaned_col_prompt = make_col_prompt(cleaned_col, example_values)\n",
    "\n",
    "#             # matching for best col\n",
    "#             ref_col, score = match_single_col_to_ref_col(cleaned_col_prompt, ref_col_lst, ref_col_embeddings, embeddings_model, embeddings_model_tokenizer)\n",
    "#             # if we still get same col\n",
    "#             if ref_col == cleaned_col_prompt: \n",
    "#                 ref_col = col\n",
    "#             if ref_col not in ref_col_to_col_lst:\n",
    "#                 ref_col_to_col_lst[ref_col] = []\n",
    "#             ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt, score))\n",
    "#         # ref_col, score = match_single_col_to_ref_col(cleaned_col_prompt, ref_col_lst, ref_col_embeddings)\n",
    "#         # if ref_col == cleaned_col_prompt: \n",
    "#         #     ref_col = col\n",
    "#         # if ref_col not in ref_col_to_col_lst:\n",
    "#         #     ref_col_to_col_lst[ref_col] = []\n",
    "#         # ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt, score))\n",
    "\n",
    "#     return ref_col_to_col_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def match_single_col_to_ref_col_with_llm(col, ref_col_lst, ref_col_embeddings):\n",
    "#     \"\"\"\n",
    "#     match a single column to reference col given column, the list of referencing col and their embeddings\n",
    "#     \"\"\"\n",
    "#     calculate column embedding\n",
    "#     col_embeddings = embeddings_model.encode(col, normalize_embeddings=True)\n",
    "#     multi_index_pattern = r\".+\\..+\"\n",
    "#     if re.search(multi_index_pattern, col):\n",
    "#         col = col.replace(\".\", \" \")\n",
    "#         # sub_col_lst = col.split(\".\")\n",
    "#         # sub_col_embeddings = create_embeddings_from_model(sub_col_lst, embeddings_model, embeddings_model_tokenizer)\n",
    "#         # col_embeddings = torch.mean(sub_col_embeddings, dim = 0)\n",
    "#         col = col.replace(\".\", \" \")\n",
    "#         col_embeddings = create_embeddings_from_model(col, embeddings_model, embeddings_model_tokenizer)\n",
    "#     else:\n",
    "#         col_embeddings = create_embeddings_from_model(col, embeddings_model, embeddings_model_tokenizer)\n",
    "#     col_embeddings = create_embeddings_from_model(col, embeddings_model, embeddings_model_tokenizer)\n",
    "#     col_embeddings = col_embeddings.reshape(-1, 1)\n",
    "\n",
    "#     calculate similarity score\n",
    "#     scores = torch.matmul(ref_col_embeddings, col_embeddings).reshape(-1)\n",
    "\n",
    "#     sort similairty score\n",
    "#     top_k_indices = torch.argsort(scores, descending=True)\n",
    "\n",
    "#     verify if we even got good enough similarity\n",
    "#     best_inx = top_k_indices[0].item()\n",
    "#     best_score = scores[best_inx].item()\n",
    "#     second_best_inx = top_k_indices[1].item()\n",
    "#     second_best_score = scores[second_best_inx].item()\n",
    "#     need a threshold for score or else, just return col\n",
    "#     if best_score < 0.4: \n",
    "#         return (col, 1)\n",
    "    \n",
    "#     # now do rerank\n",
    "#     candidates = [ref_col_lst[inx] for inx in top_k_indices if scores[inx] >= 0.4]\n",
    "#     candidates_scores = [scores[inx] for inx in top_k_indices if scores[inx] >= 0.4]\n",
    "#     best_ref_col, best_ref_col_scores = reranking_from_model(col, candidates, candidates_scores)\n",
    "#     return (best_ref_col, best_ref_col_scores)\n",
    "\n",
    "#     if best_score < 0.4:\n",
    "#         return col\n",
    "#     else:\n",
    "#         extract top 3 candidates\n",
    "#         candidates = []\n",
    "#         for i in range(3):\n",
    "#             inx = top_k_indices[i]\n",
    "#             candidates.append(ref_col_lst[inx])\n",
    "#         best_col = reranking_with_llm(col, candidates, llm_model, llm_model_tokenizer)\n",
    "#         return best_col\n",
    "\n",
    "# def match_many_col_to_ref_col_with_llm(df, ref_col_df):\n",
    "#     \"\"\"\n",
    "#     Given a list of column and a dataframe (could be dict later on if that fits better),\n",
    "#     try to match each column to the best fitted reference col, \n",
    "#     return a dict of ref col : list of (col, cleaned col prompt, score)\n",
    "#     \"\"\"\n",
    "#     prepare the embeddings for reference col since we reuse them\n",
    "#     ref_col_lst = ref_col_df[\"column\"].to_list()\n",
    "#     ref_col_context_lst = ref_col_df[\"column_with_context\"].to_list()\n",
    "#     ref_col_embeddings = create_embeddings_from_model(ref_col_context_lst, embeddings_model, embeddings_model_tokenizer)\n",
    "\n",
    "#     conduct matching\n",
    "#     multi_index_pattern = r\"^.+\\..+$\" # need multi index pattern for handling multi index\n",
    "#     ref_col_to_col_lst = {}\n",
    "#     for col in df.columns:\n",
    "\n",
    "#         extract values needed for prompt\n",
    "#         cleaned_col = clean_col(col)\n",
    "#         example_values = df[col].unique().tolist()\n",
    "#         prompt: {col}: example, need to delete all : first\n",
    "\n",
    "#         if re.search(multi_index_pattern, cleaned_col.strip()):\n",
    "#             try to assess each part and see if which one have highest score\n",
    "#             best_ref_col, best_score = None, 0\n",
    "#             best_cleaned_sub_col_prompt = None\n",
    "#             for sub_col in cleaned_col.split(\".\"):\n",
    "\n",
    "#                 make column prompt for each sub col\n",
    "#                 cleaned_sub_col_prompt = make_col_prompt(sub_col, example_values)\n",
    "                \n",
    "#                 matching and compare\n",
    "#                 ref_col, score = match_single_col_to_ref_col(cleaned_sub_col_prompt, ref_col_lst, ref_col_embeddings)\n",
    "#                 if score > best_score and ref_col != cleaned_sub_col_prompt:\n",
    "#                     best_ref_col = ref_col\n",
    "#                     best_score = score\n",
    "#                     best_cleaned_sub_col_prompt = cleaned_sub_col_prompt\n",
    "            \n",
    "#             if we have a best one vs not\n",
    "#             if best_ref_col is not None:\n",
    "#                 if best_ref_col not in ref_col_to_col_lst:\n",
    "#                     ref_col_to_col_lst[best_ref_col] = []\n",
    "#                 ref_col_to_col_lst[best_ref_col].append((col, best_cleaned_sub_col_prompt, score))\n",
    "#             else:\n",
    "#                 if col not in ref_col_to_col_lst:\n",
    "#                     ref_col_to_col_lst[col] = []\n",
    "#                 ref_col_to_col_lst[col].append((col, best_cleaned_sub_col_prompt, 1))\n",
    "#         else:\n",
    "#             match a single col with best fit referencing col and return a dict\n",
    "#             make the col prompt\n",
    "#             extra steps to remove .\n",
    "#             cleaned_col = cleaned_col.replace(\".\", \"\")\n",
    "#             cleaned_col_prompt = make_col_prompt(cleaned_col, example_values)\n",
    "\n",
    "#             matching for best col\n",
    "#             ref_col, score = match_single_col_to_ref_col(cleaned_col_prompt, ref_col_lst, ref_col_embeddings)\n",
    "#             if we still get same col\n",
    "#             if ref_col == cleaned_col_prompt: \n",
    "#                 ref_col = col\n",
    "#             if ref_col not in ref_col_to_col_lst:\n",
    "#                 ref_col_to_col_lst[ref_col] = []\n",
    "#             ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt, score))\n",
    "#         ref_col, score = match_single_col_to_ref_col(cleaned_col_prompt, ref_col_lst, ref_col_embeddings)\n",
    "#         if ref_col == cleaned_col_prompt: \n",
    "#             ref_col = col\n",
    "#         if ref_col not in ref_col_to_col_lst:\n",
    "#             ref_col_to_col_lst[ref_col] = []\n",
    "#         ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt, score))\n",
    "\n",
    "#     return ref_col_to_col_lst\n",
    "\n",
    "# def match_many_col_to_ref_col(df, ref_col_df, embeddings_model, embeddings_model_tokenizer):\n",
    "#     \"\"\"\n",
    "#     Given a list of column and a dataframe (could be dict later on if that fits better),\n",
    "#     try to match each column to the best fitted reference col, \n",
    "#     return a dict of ref col : list of (col, cleaned col prompt, score)\n",
    "#     \"\"\"\n",
    "#     prepare the embeddings for reference col since we reuse them\n",
    "#     ref_col_lst = ref_col_df[\"column\"].to_list()\n",
    "#     ref_col_context_lst = ref_col_df[\"column_with_context\"].to_list()\n",
    "#     ref_col_embeddings = create_embeddings_from_model(ref_col_context_lst, embeddings_model, embeddings_model_tokenizer)\n",
    "\n",
    "#     conduct matching\n",
    "#     multi_index_pattern = r\"^.+\\..+$\" # need multi index pattern for handling multi index\n",
    "#     ref_col_to_col_lst = {}\n",
    "#     for col in df.columns:\n",
    "\n",
    "#         extract values needed for prompt\n",
    "#         cleaned_col = clean_col(col)\n",
    "#         example_values = df[col].unique().tolist()\n",
    "#         prompt: {col}: example, need to delete all : first\n",
    "\n",
    "#         if re.search(multi_index_pattern, cleaned_col.strip()):\n",
    "#             try to assess each part and see if which one have highest score\n",
    "#             best_ref_col, best_score = None, 0\n",
    "#             best_cleaned_sub_col_prompt = None\n",
    "#             for sub_col in cleaned_col.split(\".\"):\n",
    "\n",
    "#                 make column prompt for each sub col\n",
    "#                 cleaned_sub_col_prompt = make_col_prompt(sub_col, example_values)\n",
    "                \n",
    "#                 matching and compare\n",
    "#                 ref_col, score = match_single_col_to_ref_col(cleaned_sub_col_prompt, ref_col_lst, ref_col_embeddings, embeddings_model, embeddings_model_tokenizer)\n",
    "#                 if score > best_score and ref_col != cleaned_sub_col_prompt:\n",
    "#                     best_ref_col = ref_col\n",
    "#                     best_score = score\n",
    "#                     best_cleaned_sub_col_prompt = cleaned_sub_col_prompt\n",
    "            \n",
    "#             if we have a best one vs not\n",
    "#             if best_ref_col is not None:\n",
    "#                 if best_ref_col not in ref_col_to_col_lst:\n",
    "#                     ref_col_to_col_lst[best_ref_col] = []\n",
    "#                 ref_col_to_col_lst[best_ref_col].append((col, best_cleaned_sub_col_prompt, score))\n",
    "#             else:\n",
    "#                 if col not in ref_col_to_col_lst:\n",
    "#                     ref_col_to_col_lst[col] = []\n",
    "#                 ref_col_to_col_lst[col].append((col, best_cleaned_sub_col_prompt, 1))\n",
    "#         else:\n",
    "#             match a single col with best fit referencing col and return a dict\n",
    "#             make the col prompt\n",
    "#             extra steps to remove .\n",
    "#             cleaned_col = cleaned_col.replace(\".\", \"\")\n",
    "#             cleaned_col_prompt = make_col_prompt(cleaned_col, example_values)\n",
    "\n",
    "#             matching for best col\n",
    "#             ref_col, score = match_single_col_to_ref_col(cleaned_col_prompt, ref_col_lst, ref_col_embeddings, embeddings_model, embeddings_model_tokenizer)\n",
    "#             if we still get same col\n",
    "#             if ref_col == cleaned_col_prompt: \n",
    "#                 ref_col = col\n",
    "#             if ref_col not in ref_col_to_col_lst:\n",
    "#                 ref_col_to_col_lst[ref_col] = []\n",
    "#             ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt, score))\n",
    "#         ref_col, score = match_single_col_to_ref_col(cleaned_col_prompt, ref_col_lst, ref_col_embeddings)\n",
    "#         if ref_col == cleaned_col_prompt: \n",
    "#             ref_col = col\n",
    "#         if ref_col not in ref_col_to_col_lst:\n",
    "#             ref_col_to_col_lst[ref_col] = []\n",
    "#         ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt, score))\n",
    "\n",
    "#     return ref_col_to_col_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251adf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in os.listdir(\"./tables\"):\n",
    "#     if \"table\" in file and \".csv\" in file and \"harmonized\" not in file:\n",
    "#         print(file)\n",
    "#         df = pd.read_csv(f\"./tables/{file}\")\n",
    "#         df.columns = ['' if 'Unnamed:' in col else col for col in df.columns]\n",
    "#         col_to_ref_col = match_many_col_to_ref_col(df, referencing_cols)\n",
    "#         for ref_col in col_to_ref_col:\n",
    "#             print(f\"{ref_col}: {col_to_ref_col[ref_col]}\")\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e05fd",
   "metadata": {},
   "source": [
    "Rewrite the matching engine as an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df52f137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>description</th>\n",
       "      <th>is_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNP</td>\n",
       "      <td>Variant identifier, or snp idenifier, or chr:p...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chr</td>\n",
       "      <td>Genomic chromosome identifier. Keywords: CHR, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Position</td>\n",
       "      <td>Genomic coordinate location. Keywords: BP, POS...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RA</td>\n",
       "      <td>The allele associated with the effect or risk....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF</td>\n",
       "      <td>Frequency of the reported allele in the sample...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P-value</td>\n",
       "      <td>The statistical significance of the associatio...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Effect Size</td>\n",
       "      <td>The magnitude and direction of the association...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        column                                        description  is_numeric\n",
       "0          SNP  Variant identifier, or snp idenifier, or chr:p...       False\n",
       "1          Chr  Genomic chromosome identifier. Keywords: CHR, ...       False\n",
       "2     Position  Genomic coordinate location. Keywords: BP, POS...       False\n",
       "3           RA  The allele associated with the effect or risk....       False\n",
       "4           AF  Frequency of the reported allele in the sample...        True\n",
       "5      P-value  The statistical significance of the associatio...        True\n",
       "6  Effect Size  The magnitude and direction of the association...        True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now try to map the columns with the actual col in advp\n",
    "referencing_cols = pd.read_csv(\"Rules for harmonizing ADVP papers - Main cols.csv\")\n",
    "referencing_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b3c26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTokenBiasProcessor(LogitsProcessor):\n",
    "    def __init__(self, token_ids, bias_value):\n",
    "        self.token_ids = token_ids\n",
    "        self.bias_value = bias_value\n",
    "\n",
    "    def __call__(self, input_ids, scores):\n",
    "        # Create a mask for allowed tokens\n",
    "        mask = torch.full_like(scores, -float(\"inf\"))\n",
    "        for tid in self.token_ids:\n",
    "            mask[:, tid] = self.bias_value\n",
    "        return scores + mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8609ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GWASColumnMatchingEngine:\n",
    "    def __init__(self, referencing_col_df: pd.DataFrame, embeddings_model_name: str = \"NeuML/pubmedbert-base-embeddings\", \n",
    "                 use_llm: bool = False, llm_model_name: str = \"stanford-crfm/BioMedLM\", device: str = \"cpu\"):\n",
    "        # df of referencing col\n",
    "        if not (\"column\" in referencing_col_df.columns and \"description\" in referencing_col_df.columns):\n",
    "            raise Exception(\"Error: Dataframe for referencing columns need to have 2 columns: column and description\")\n",
    "        self.referencing_col_lst = referencing_col_df[\"column\"].to_list()\n",
    "        self.referencing_col_context_lst = referencing_col_df.apply(lambda x: x[\"column\"] if pd.isna(x[\"description\"]) else x[\"column\"] + \": \" + x[\"description\"], axis = 1).to_list()\n",
    "        if use_llm:\n",
    "            self.referencing_col_to_col_context = {c: cc for c, cc in zip(self.referencing_col_lst, self.referencing_col_context_lst)}\n",
    "            self.referencing_col_context_to_col = {cc: c for c, cc in zip(self.referencing_col_lst, self.referencing_col_context_lst)}\n",
    "\n",
    "        # Try to first convert any abbreviation, then we match column with right semantic\n",
    "        self.gwas_abbreviation_dict = {\n",
    "            \"CHR\": \"Chromosome number\",\n",
    "            \"BP\": \"Base-pair position\",\n",
    "            \"POS\": \"Position\",\n",
    "            \"SNP\": \"Single nucleotide polymorphism identifier\",\n",
    "            \"RS\": \"Reference Single nucleotide polymorphism\",\n",
    "            \"VAR\": \"Variant\",\n",
    "            \"ID\": \"identifier\",\n",
    "            \"A1\": \"Effect allele / tested allele\",\n",
    "            \"A2\": \"Other allele / non-effect allele\",\n",
    "            \"REF\": \"Reference allele (genome reference)\",\n",
    "            \"ALT\": \"Alternate allele\",\n",
    "            \"EA\": \"Effect Allele\",\n",
    "            \"NEA\": \"Non-Effect Allele\",\n",
    "            \"RA\": \"Risk Allele\",\n",
    "            \"OA\": \"Other Allele\",\n",
    "            \"AF\": \"Allele Frequency (general term)\",\n",
    "            \"RAF\": \"Risk Allele Frequency\",\n",
    "            \"EAF\": \"Effect Allele Frequency\",\n",
    "            \"MAF\": \"Minor Allele Frequency\",\n",
    "            \"BETA\": \"Effect size (regression coefficient)\",\n",
    "            \"OR\": \"Odds Ratio\",\n",
    "            \"SE\": \"Standard Error of effect estimate\",\n",
    "            \"Z\": \"Z-score statistic\",\n",
    "            \"T\": \"T-statistic\",\n",
    "            \"CI\": \"Confidence Interval\",\n",
    "            \"P\": \"P-value\",\n",
    "            \"PVAL\": \"P-value\",\n",
    "            \"LOGP\": \"Negative log10 P-value\",\n",
    "            \"Q\": \"Heterogeneity statistic (meta-analysis)\",\n",
    "            \"I2\": \"I-squared heterogeneity metric\",\n",
    "            \"HWE\": \"Hardy-Weinberg Equilibrium test statistic\",\n",
    "            \"INFO\": \"Imputation quality score\",\n",
    "            \"R2\": \"Imputation accuracy metric\",\n",
    "            \"CALLRATE\": \"Genotype call rate\",\n",
    "            \"MISSING\": \"Missing genotype rate\",\n",
    "            \"N\": \"Total sample size\",\n",
    "            \"N_CASES\": \"Number of cases (for binary traits)\",\n",
    "            \"N_CONTROLS\": \"Number of controls (for binary traits)\",\n",
    "            \"EUR\": \"European ancestry\",\n",
    "            \"AFR\": \"African ancestry\",\n",
    "            \"ASN\": \"Asian ancestry\",\n",
    "            \"AMR\": \"Admixed American ancestry\",\n",
    "            \"SAS\": \"South Asian ancestry\",\n",
    "            \"EAS\": \"East Asian ancestry\",\n",
    "            \"LD\": \"Linkage Disequilibrium\",\n",
    "            \"DPRIME\": \"LD D’ value\",\n",
    "            \"CADD\": \"CADD score (functional impact)\",\n",
    "            \"EQTL\": \"Expression quantitative trait locus\",\n",
    "            \"PQTL\": \"Protein QTL\",\n",
    "            \"GWGAS\": \"Gene-wide association study\",\n",
    "            \"PRS\": \"Polygenic Risk Score\",\n",
    "            \"PGS\": \"Polygenic Score\",\n",
    "            \"QC\": \"Quality Control\",\n",
    "            \"MA\": \"Meta-analysis\",\n",
    "            \"HLA\": \"Human Leukocyte Antigen region\",\n",
    "            \"HR\": \"Hazard ratio\",\n",
    "            \"HET\": \"Heterogeneity test\",\n",
    "            \"APOE4\": \"APOE ε4\",\n",
    "            \"APOE*4\": \"APOE ε4\",\n",
    "            \"#\": \"Number of\",\n",
    "            \"frq\": \"Frequency\",\n",
    "            'β': \"Effect\",\n",
    "            \"nsnps\": \"Number of Variants\"\n",
    "        }\n",
    "\n",
    "        # embeddings model\n",
    "        self.embeddings_model_tokenizer = AutoTokenizer.from_pretrained(embeddings_model_name)\n",
    "        self.embeddings_model = AutoModel.from_pretrained(embeddings_model_name)\n",
    "        self.embeddings_model.eval()\n",
    "\n",
    "        # also make col embeddings\n",
    "        self.referencing_col_embeddings = self.create_col_embeddings_from_model(self.referencing_col_context_lst)\n",
    "\n",
    "        # llm model\n",
    "        self.use_llm = use_llm\n",
    "        if use_llm:\n",
    "            self.llm_model_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "            self.llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "                llm_model_name,\n",
    "                dtype=torch.bfloat16\n",
    "            ).to(device)\n",
    "            self.llm_model.eval()\n",
    "\n",
    "        # device\n",
    "        self.device = device\n",
    "\n",
    "    def clean_col(self, col: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean a column by replacing any possible abbreviation with their actual meaning for better semantic matching\n",
    "        \"\"\"\n",
    "        new_col = col\n",
    "        for abb in self.gwas_abbreviation_dict:\n",
    "            if re.search(fr\"[^a-zA-Z]{abb.lower()}[^a-zA-Z]\", new_col.lower()):\n",
    "                new_col = re.sub(fr\"([^a-zA-Z]){abb.lower()}([^a-zA-Z])\", fr\"\\1{self.gwas_abbreviation_dict[abb]}\\2\", new_col.lower())\n",
    "            elif re.search(fr\"^{abb.lower()}[^a-zA-Z]\", new_col.lower()):\n",
    "                new_col = re.sub(fr\"^{abb.lower()}([^a-zA-Z])\", fr\"{self.gwas_abbreviation_dict[abb]}\\1\", new_col.lower())\n",
    "            elif re.search(fr\"[^a-zA-Z]{abb.lower()}$\", new_col.lower()):\n",
    "                new_col = re.sub(fr\"([^a-zA-Z]){abb.lower()}$\", fr\"\\1{self.gwas_abbreviation_dict[abb]}\", new_col.lower())\n",
    "            elif re.search(fr\"^{abb.lower()}$\", new_col.lower()):\n",
    "                new_col = re.sub(fr\"{abb.lower()}\", self.gwas_abbreviation_dict[abb], new_col.lower())\n",
    "        # new_col = new_col.replace(\".\", \" \")\n",
    "        return new_col\n",
    "    \n",
    "    def make_col_prompt(self, col: str, example_values: Iterable, num_example_values: int = 5) -> str:\n",
    "        \"\"\"\n",
    "        Based on the column title and some possible values of that columns, try to make a prompt\n",
    "        \"\"\"\n",
    "        col_prompt = f\"{col}: \"\n",
    "        for i in range(min(num_example_values, len(example_values))):\n",
    "            col_prompt += f\"{example_values[i]}, \"\n",
    "        return col_prompt\n",
    "\n",
    "    def create_col_embeddings_from_model(self, col: str | List[str]) -> np.ndarray | torch.Tensor:\n",
    "        \"\"\"\n",
    "        Create embeddings from string represent col name or a prompt of that col\n",
    "        \"\"\"\n",
    "        input = self.embeddings_model_tokenizer(col, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "        # get token embeddings\n",
    "        with torch.no_grad():\n",
    "            output = self.embeddings_model(**input)\n",
    "        token_embeddings = output[0]\n",
    "\n",
    "        # extract mask and mean pooling for sentence embeddings\n",
    "        input_mask_expanded = input['attention_mask'].unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        col_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "        # final normalization\n",
    "        col_embeddings = F.normalize(col_embeddings, p=2, dim=1)\n",
    "\n",
    "        return col_embeddings\n",
    "    \n",
    "    def reranking_with_llm(self, col: str, candidates: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        LLM acts as a re-ranker to pick the best match from a list of candidates.\n",
    "        \"\"\"\n",
    "        if not self.use_llm:\n",
    "            raise Exception(\"LLM use has not been enabled in the model, please re-init with use_llm=True\")\n",
    "        \n",
    "        # Format the candidates as a numbered list for the LLM\n",
    "        candidates_str = \"\\n\".join([f\"\\t{inx+1}. {c}\" for inx, c in enumerate(candidates)])\n",
    "        prompt = f\"\"\"Task: Map clinical table headers to GWAS standard ontology, return a single number for the best choice\n",
    "\n",
    "Header: \"p-value: 0.001, 5e-8, 0.43\"\n",
    "Candidates: \n",
    "    1. P-value: The statistical significance of the association. Keywords: P, P-value, P_adj, FDR. Examples: 5.0E-08, 0.0012, 1.2 x 10^-5, 0.05.\n",
    "    2. Effect Size: The magnitude and direction of the association. Keywords: Beta, OR, HR, Estimate. Examples: Beta=0.25, OR=1.45, HR=1.12, Log(OR)=0.37.\n",
    "    3. SNP: Variant identifier, or snp idenifier, or chr:pos. Keywords: chr:position, chr:pos, Variant, rsID, RS number, MarkerName, rs. Examples: rs12345, 20:45269867, 19:45411941:T:C, chr19:45411941, rs429358 (APOE ε4).\n",
    "Best Match: 1\n",
    "\n",
    "Header: \"rs_number: rs123, rs456, rs789\"\n",
    "Candidates: \n",
    "    1. Chr: Genomic chromosome identifier. Keywords: CHR, Chrom, Chromosome. Examples: 1, 19, X, chr19, chrX.\n",
    "    2. Position: Genomic coordinate location. Keywords: BP, POS, Base Pair, start, end. Examples: 45411941, 10240500:10248600 (range), build 37.\n",
    "    3. SNP: Variant identifier, or snp idenifier, or chr:pos. Keywords: chr:position, chr:pos, Variant, rsID, RS number, MarkerName, rs. Examples: rs12345, 20:45269867, 19:45411941:T:C, chr19:45411941, rs429358 (APOE ε4).\n",
    "Best Match: 2\n",
    "\n",
    "Header: \"{col}\"\n",
    "Candidates: \n",
    "{candidates_str}\n",
    "Best Match: \"\"\"\n",
    "\n",
    "        allowed_indices = [str(i+1) for i in range(len(candidates))]\n",
    "        allowed_token_ids = [self.llm_model_tokenizer.encode(idx, add_special_tokens=False)[0] for idx in allowed_indices]\n",
    "        \n",
    "        # logit bias to limit tokens that can be output\n",
    "        bias_processor = SingleTokenBiasProcessor(allowed_token_ids, 100.0)\n",
    "        logits_processor = LogitsProcessorList([bias_processor])\n",
    "\n",
    "        # 4. Generate exactly ONE token\n",
    "        inputs = self.llm_model_tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.llm_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1,      # Force exactly one token\n",
    "                logits_processor=logits_processor, # Force it to be one of our numbers\n",
    "                pad_token_id=self.llm_model_tokenizer.eos_token_id,\n",
    "                do_sample=False        # Greedy decoding for consistency\n",
    "            )\n",
    "\n",
    "        # 5. Extract and Convert to Integer\n",
    "        new_token = output[0][-1]\n",
    "        predicted_text = self.llm_model_tokenizer.decode(new_token).strip()\n",
    "        \n",
    "        try:\n",
    "            idx = int(predicted_text) - 1 # Convert back to 0-based list index\n",
    "            return candidates[idx]\n",
    "        except (ValueError, IndexError):\n",
    "            return col\n",
    "        \n",
    "    def identify_main_role_in_multi_index_col(self, col: str) -> str:\n",
    "        sub_col = col.split(\".\")\n",
    "        candidates = []\n",
    "        for i in range(len(sub_col)):\n",
    "            main_role = f\"{sub_col[i]} of \"\n",
    "            context = \" and \".join([sub_col[j] for j in range(len(sub_col)) if j != i])\n",
    "            main_role_and_context = main_role + context\n",
    "            candidates.append(main_role_and_context)\n",
    "        # make candidate str\n",
    "        candidates_str = \"\\n\".join([f\"\\t{inx+1}. {c}\" for inx, c in enumerate(candidates)])\n",
    "        prompt = f\"\"\"Task: Figure out which is the real meaning of the column in gwas table, return a number for the best choice\n",
    "\n",
    "Candidates: \n",
    "    1. Multi-ethnic meta-analysis of Effect\n",
    "    2. Effect of Multi-ethnic meta-analysis\n",
    "Best Match: 2\n",
    "\n",
    "Candidates: \n",
    "    1. p -value (10,000 permutations) of APOE *4 + females\n",
    "    2. APOE *4 + females of p -value (10,000 permutations) \n",
    "Best Match: 1\n",
    "\n",
    "Candidates:\n",
    "    1. GWASmeta-analysis or chr:position\n",
    "    2. chr:position or GWASmeta-analysis\n",
    "Best Match: 2\n",
    "\n",
    "Candidates: \n",
    "{candidates_str}\n",
    "Best Match: \"\"\"\n",
    "        \n",
    "        allowed_indices = [str(i+1) for i in range(len(candidates))]\n",
    "        allowed_token_ids = [self.llm_model_tokenizer.encode(idx, add_special_tokens=False)[0] for idx in allowed_indices]\n",
    "        \n",
    "        # logit bias to limit tokens that can be output\n",
    "        bias_processor = SingleTokenBiasProcessor(allowed_token_ids, 100.0)\n",
    "        logits_processor = LogitsProcessorList([bias_processor])\n",
    "\n",
    "        # 4. Generate exactly ONE token\n",
    "        inputs = self.llm_model_tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.llm_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1,      # Force exactly one token\n",
    "                logits_processor=logits_processor, # Force it to be one of our numbers\n",
    "                pad_token_id=self.llm_model_tokenizer.eos_token_id,\n",
    "                do_sample=False        # Greedy decoding for consistency\n",
    "            )\n",
    "\n",
    "        # 5. Extract and Convert to Integer\n",
    "        new_token = output[0][-1]\n",
    "        predicted_text = self.llm_model_tokenizer.decode(new_token).strip()\n",
    "        \n",
    "        try:\n",
    "            idx = int(predicted_text) - 1 # Convert back to 0-based list index\n",
    "            return sub_col[idx]\n",
    "        except (ValueError, IndexError):\n",
    "            return col\n",
    "        \n",
    "    def match_single_col_to_ref_col(self, col: str) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        match a single column to reference col given column, the list of referencing col and their embeddings\n",
    "        \"\"\"\n",
    "        # calculate column embedding\n",
    "        # col_embeddings = embeddings_model.encode(col, normalize_embeddings=True)\n",
    "        # multi_index_pattern = r\".+\\..+\"\n",
    "        # if re.search(multi_index_pattern, col):\n",
    "        #     col = col.replace(\".\", \" \")\n",
    "        #     # sub_col_lst = col.split(\".\")\n",
    "        #     # sub_col_embeddings = create_embeddings_from_model(sub_col_lst, embeddings_model, embeddings_model_tokenizer)\n",
    "        #     # col_embeddings = torch.mean(sub_col_embeddings, dim = 0)\n",
    "        #     col = col.replace(\".\", \" \")\n",
    "        #     col_embeddings = create_embeddings_from_model(col, embeddings_model, embeddings_model_tokenizer)\n",
    "        # else:\n",
    "        #     col_embeddings = create_embeddings_from_model(col, embeddings_model, embeddings_model_tokenizer)\n",
    "        col_embeddings = self.create_col_embeddings_from_model(col)\n",
    "        col_embeddings = col_embeddings.reshape(-1, 1)\n",
    "\n",
    "        # calculate similarity score\n",
    "        scores = torch.matmul(self.referencing_col_embeddings, col_embeddings).reshape(-1)\n",
    "\n",
    "        # sort similairty score\n",
    "        top_k_indices = torch.argsort(scores, descending=True)\n",
    "\n",
    "        # verify if we even got good enough similarity\n",
    "        best_inx = top_k_indices[0].item()\n",
    "        best_score = scores[best_inx].item()\n",
    "        # second_best_inx = top_k_indices[1].item()\n",
    "        # second_best_score = scores[second_best_inx].item()\n",
    "        # need a threshold for score or else, just return col\n",
    "        # if best_score < 0.4: \n",
    "        #     return (col, 1)\n",
    "        \n",
    "        # # now do rerank\n",
    "        # candidates = [ref_col_lst[inx] for inx in top_k_indices if scores[inx] >= 0.4]\n",
    "        # candidates_scores = [scores[inx] for inx in top_k_indices if scores[inx] >= 0.4]\n",
    "        # best_ref_col, best_ref_col_scores = reranking_from_model(col, candidates, candidates_scores)\n",
    "        # return (best_ref_col, best_ref_col_scores)\n",
    "\n",
    "        if best_score >= 0.4:\n",
    "            return (self.referencing_col_lst[best_inx], best_score)\n",
    "        return (col, 1)\n",
    "\n",
    "    def match_many_col_to_ref_col(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        Given a list of column and a dataframe (could be dict later on if that fits better),\n",
    "        try to match each column to the best fitted reference col, \n",
    "        return a dict of ref col : list of (col, cleaned col prompt, score)\n",
    "        \"\"\"\n",
    "\n",
    "        # conduct matching\n",
    "        multi_index_pattern = r\"^.+\\..+$\" # need multi index pattern for handling multi index\n",
    "        ref_col_to_col_lst = {}\n",
    "        for col in df.columns:\n",
    "\n",
    "            # extract values needed for prompt\n",
    "            cleaned_col = self.clean_col(col)\n",
    "            example_values = df[col].unique().tolist()\n",
    "            # prompt: {col}: example, need to delete all : first\n",
    "\n",
    "            if re.search(multi_index_pattern, cleaned_col.strip()):\n",
    "                # try to assess each part and see if which one have highest score\n",
    "                best_ref_col, best_score = None, 0\n",
    "                best_cleaned_sub_col_prompt = None\n",
    "                for sub_col in cleaned_col.split(\".\"):\n",
    "\n",
    "                    # make column prompt for each sub col\n",
    "                    cleaned_sub_col_prompt = self.make_col_prompt(sub_col, example_values)\n",
    "                    \n",
    "                    # matching and compare\n",
    "                    ref_col, score = self.match_single_col_to_ref_col(cleaned_sub_col_prompt)\n",
    "                    if score > best_score and ref_col != cleaned_sub_col_prompt:\n",
    "                        best_ref_col = ref_col\n",
    "                        best_score = score\n",
    "                        best_cleaned_sub_col_prompt = cleaned_sub_col_prompt\n",
    "                \n",
    "                # if we have a best one vs not\n",
    "                if best_ref_col is not None:\n",
    "                    if best_ref_col not in ref_col_to_col_lst:\n",
    "                        ref_col_to_col_lst[best_ref_col] = []\n",
    "                    ref_col_to_col_lst[best_ref_col].append((col, best_cleaned_sub_col_prompt, score))\n",
    "                else:\n",
    "                    if col not in ref_col_to_col_lst:\n",
    "                        ref_col_to_col_lst[col] = []\n",
    "                    ref_col_to_col_lst[col].append((col, best_cleaned_sub_col_prompt, 1))\n",
    "            else:\n",
    "                # match a single col with best fit referencing col and return a dict\n",
    "                # make the col prompt\n",
    "                # extra steps to remove .\n",
    "                cleaned_col = cleaned_col.replace(\".\", \"\")\n",
    "                cleaned_col_prompt = self.make_col_prompt(cleaned_col, example_values)\n",
    "\n",
    "                # matching for best col\n",
    "                ref_col, score = self.match_single_col_to_ref_col(cleaned_col_prompt)\n",
    "                # if we still get same col\n",
    "                if ref_col == cleaned_col_prompt: \n",
    "                    ref_col = col\n",
    "                if ref_col not in ref_col_to_col_lst:\n",
    "                    ref_col_to_col_lst[ref_col] = []\n",
    "                ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt, score))\n",
    "            # ref_col, score = match_single_col_to_ref_col(cleaned_col_prompt, ref_col_lst, ref_col_embeddings)\n",
    "            # if ref_col == cleaned_col_prompt: \n",
    "            #     ref_col = col\n",
    "            # if ref_col not in ref_col_to_col_lst:\n",
    "            #     ref_col_to_col_lst[ref_col] = []\n",
    "            # ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt, score))\n",
    "\n",
    "        return ref_col_to_col_lst\n",
    "    \n",
    "    def match_single_col_to_ref_col_with_llm(self, col: str, num_candidates: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        match a single column to reference col given column, the list of referencing col and their embeddings\n",
    "        \"\"\"\n",
    "        if not self.use_llm:\n",
    "            raise Exception(\"LLM use has not been enabled in the model, please re-init with use_llm=True\")\n",
    "        \n",
    "        # calculate column embedding\n",
    "        # col_embeddings = embeddings_model.encode(col, normalize_embeddings=True)\n",
    "        # multi_index_pattern = r\".+\\..+\"\n",
    "        # if re.search(multi_index_pattern, col):\n",
    "        #     col = col.replace(\".\", \" \")\n",
    "        #     # sub_col_lst = col.split(\".\")\n",
    "        #     # sub_col_embeddings = create_embeddings_from_model(sub_col_lst, embeddings_model, embeddings_model_tokenizer)\n",
    "        #     # col_embeddings = torch.mean(sub_col_embeddings, dim = 0)\n",
    "        #     col = col.replace(\".\", \" \")\n",
    "        #     col_embeddings = create_embeddings_from_model(col, embeddings_model, embeddings_model_tokenizer)\n",
    "        # else:\n",
    "        #     col_embeddings = create_embeddings_from_model(col, embeddings_model, embeddings_model_tokenizer)\n",
    "        col_embeddings = self.create_col_embeddings_from_model(col)\n",
    "        col_embeddings = col_embeddings.reshape(-1, 1)\n",
    "\n",
    "        # calculate similarity score\n",
    "        scores = torch.matmul(self.referencing_col_embeddings, col_embeddings).reshape(-1)\n",
    "\n",
    "        # sort similairty score\n",
    "        top_k_indices = torch.argsort(scores, descending=True)\n",
    "\n",
    "        # verify if we even got good enough similarity\n",
    "        best_inx = top_k_indices[0].item()\n",
    "        best_score = scores[best_inx].item()\n",
    "        # second_best_inx = top_k_indices[1].item()\n",
    "        # second_best_score = scores[second_best_inx].item()\n",
    "        # need a threshold for score or else, just return col\n",
    "        # if best_score < 0.4: \n",
    "        #     return (col, 1)\n",
    "        \n",
    "        # # now do rerank\n",
    "        # candidates = [ref_col_lst[inx] for inx in top_k_indices if scores[inx] >= 0.4]\n",
    "        # candidates_scores = [scores[inx] for inx in top_k_indices if scores[inx] >= 0.4]\n",
    "        # best_ref_col, best_ref_col_scores = reranking_from_model(col, candidates, candidates_scores)\n",
    "        # return (best_ref_col, best_ref_col_scores)\n",
    "\n",
    "        if best_score < 0.4:\n",
    "            return col\n",
    "        else:\n",
    "            # extract top 3 candidates\n",
    "            candidates = []\n",
    "            for i in range(num_candidates):\n",
    "                inx = top_k_indices[i]\n",
    "                # need to add the column with context, not just column\n",
    "                candidates.append(self.referencing_col_context_lst[inx])\n",
    "            best_col = self.reranking_with_llm(col, candidates)\n",
    "            # after this, map back to normal column\n",
    "            if best_col in self.referencing_col_context_to_col:\n",
    "                best_col = self.referencing_col_context_to_col[best_col]\n",
    "            return best_col\n",
    "\n",
    "    def match_many_col_to_ref_col_with_llm(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        Given a list of column and a dataframe (could be dict later on if that fits better),\n",
    "        try to match each column to the best fitted reference col, \n",
    "        return a dict of ref col : list of (col, cleaned col prompt, score)\n",
    "        \"\"\"\n",
    "        if not self.use_llm:\n",
    "            raise Exception(\"LLM use has not been enabled in the model, please re-init with use_llm=True\")\n",
    "        \n",
    "        # prepare the embeddings for reference col since we reuse them\n",
    "        # conduct matching\n",
    "        multi_index_pattern = r\"^.+\\..+$\" # need multi index pattern for handling multi index\n",
    "        ref_col_to_col_lst = {}\n",
    "        for col in df.columns:\n",
    "\n",
    "            # extract values needed for prompt\n",
    "            cleaned_col = self.clean_col(col)\n",
    "            example_values = df[col].unique().tolist()\n",
    "            # prompt: {col}: example, need to delete all : first\n",
    "\n",
    "            # if re.search(multi_index_pattern, cleaned_col.strip()):\n",
    "            #     # try to assess each part and see if which one have highest score\n",
    "            #     best_candidates = []\n",
    "            #     for sub_col in cleaned_col.split(\".\"):\n",
    "\n",
    "            #         # make column prompt for each sub col\n",
    "            #         cleaned_sub_col_prompt = self.make_col_prompt(sub_col, example_values)\n",
    "                    \n",
    "            #         # matching and compare\n",
    "            #         ref_col = self.match_single_col_to_ref_col_with_llm(cleaned_sub_col_prompt)\n",
    "            #         # need to convert because we do the reranking again later, we must convert to col with context\n",
    "            #         if ref_col in self.referencing_col_to_col_context:\n",
    "            #             best_candidates.append(self.referencing_col_to_col_context[ref_col])\n",
    "            #         else:\n",
    "            #             best_candidates.append(ref_col)\n",
    "            #     # if we have a best one vs not\n",
    "            #     if len(best_candidates) > 0:\n",
    "            #         cleaned_col = cleaned_col.replace(\".\", \" \")\n",
    "            #         cleaned_col_prompt = self.make_col_prompt(cleaned_col, example_values)\n",
    "            #         best_ref_col = self.reranking_with_llm(cleaned_col_prompt, best_candidates)\n",
    "\n",
    "            #         # after getting best ref col, since it is still col with context, need converting back\n",
    "            #         if best_ref_col in self.referencing_col_context_to_col:\n",
    "            #             best_ref_col = self.referencing_col_context_to_col[best_ref_col]\n",
    "\n",
    "            #         if best_ref_col not in ref_col_to_col_lst:\n",
    "            #             ref_col_to_col_lst[best_ref_col] = []\n",
    "            #         ref_col_to_col_lst[best_ref_col].append((col, cleaned_col_prompt))\n",
    "            #     else:\n",
    "            #         if col not in ref_col_to_col_lst:\n",
    "            #             ref_col_to_col_lst[col] = []\n",
    "            #         ref_col_to_col_lst[col].append((col, None))\n",
    "            # else:\n",
    "            #     # match a single col with best fit referencing col and return a dict\n",
    "            #     # make the col prompt\n",
    "            #     # extra steps to remove .\n",
    "            #     cleaned_col = cleaned_col.replace(\".\", \"\")\n",
    "            #     cleaned_col_prompt = self.make_col_prompt(cleaned_col, example_values)\n",
    "\n",
    "            #     # matching for best col\n",
    "            #     ref_col = self.match_single_col_to_ref_col_with_llm(cleaned_col_prompt)\n",
    "            #     # if we still get same col\n",
    "            #     if ref_col == cleaned_col_prompt: \n",
    "            #         ref_col = col\n",
    "            #     if ref_col not in ref_col_to_col_lst:\n",
    "            #         ref_col_to_col_lst[ref_col] = []\n",
    "            #     ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt))\n",
    "            # ref_col, score = match_single_col_to_ref_col(cleaned_col_prompt, ref_col_lst, ref_col_embeddings)\n",
    "            # if ref_col == cleaned_col_prompt: \n",
    "            #     ref_col = col\n",
    "            # if ref_col not in ref_col_to_col_lst:\n",
    "            #     ref_col_to_col_lst[ref_col] = []\n",
    "            # ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt, score))\n",
    "\n",
    "            if re.search(multi_index_pattern, cleaned_col.strip()):\n",
    "                main_role = self.identify_main_role_in_multi_index_col(cleaned_col)\n",
    "                cleaned_col_prompt = self.make_col_prompt(main_role, example_values)\n",
    "            else:\n",
    "                cleaned_col = cleaned_col.replace(\".\", \"\")\n",
    "                cleaned_col_prompt = self.make_col_prompt(cleaned_col, example_values)\n",
    "            ref_col, score = self.match_single_col_to_ref_col(cleaned_col_prompt)\n",
    "            # if we still get same col\n",
    "            if ref_col == cleaned_col_prompt: \n",
    "                ref_col = col\n",
    "            if ref_col not in ref_col_to_col_lst:\n",
    "                ref_col_to_col_lst[ref_col] = []\n",
    "            ref_col_to_col_lst[ref_col].append((col, cleaned_col_prompt, score))\n",
    "\n",
    "        return ref_col_to_col_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408c1a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s42003-019-0537-9_table_1.csv\n",
      "Lobe.: [('Lobe.', 'Lobe: Parietal, Temporal, Occipital, ', 1)]\n",
      "Position: [('Annotation (nearby).', 'Annotation (nearby): UTR3, Intronic, Intergenic, Upstream, ', 0.6019756197929382), ('Gene.', 'Gene: ZIC4, MSRB3, DAAM1 (dist = 24302), FGFRL1, CENPW (dist = 175626), ', 0.4209498167037964), ('Position.', 'Position: 147106319, 65793942, 59631075, 1013382, 126845380, ', 0.5123593807220459)]\n",
      "SNP: [('Rs-ID.', 'reference single nucleotide polymorphism-identifier: rs2279829, rs146354218, rs147148763, rs74921869, rs1337736, ', 0.6220928430557251)]\n",
      "Chr: [('Chr.', 'Chromosome number: 3, 12, 14, 4, 6, ', 0.6646982431411743)]\n",
      "RA: [('A1.', 'Effect allele / tested allele: T, A, G, ', 0.6893496513366699), ('A2.', 'Other allele / non-effect allele: C, G, GTTGT, ', 0.5696173906326294)]\n",
      "AF: [('European ancestry meta-analysis.Frq', 'european ancestry meta-analysis: 0.21, 0.37, 0.13, 0.2, 0.23, ', 0.4252067506313324), ('European ancestry meta-analysis.Effect', 'European ancestry meta-analysis: - 0.92, 0.69, - 0.83, - 0.84, - 0.64, ', 0.4634610414505005), ('European ancestry meta-analysis.SE', 'european ancestry meta-analysis: 0.16, 0.11, 0.14, 0.12, 0.1, ', 0.5398542284965515), ('Multi-ethnic meta-analysis.Frq', 'Frequency: 0.21, 0.37, 0.13, 0.2, 0.23, ', 0.4252067506313324), ('Replication sample ( n = 8,789).R 2 (%)', 'replication sample ( Total sample size = 8,789): 0.24, 0.23 0.12, 0.27, 0.19, 0.17, ', 1), ('Replication sample ( n = 8,789).Frq', 'Frequency: 0.22, - 0.37 0.54, - 0.80, 0.19 - 0.22, 0.23 - 0.46, ', 0.4252720773220062)]\n",
      "P-value: [('European ancestry meta-analysis.p', 'P-value: 5.3 × 10 - 9, 1.2 × 10 - 9, 6.6 × 10 - 9, 5.9 × 10 - 9, 8.1 × 10 - 8, ', 0.5993689894676208), ('Multi-ethnic meta-analysis.p', 'P-value: 4.4 × 10 - 10, 6.4 × 10 - 10, 2.9 × 10 - 9, 6.2 × 10 - 9, 4.0 × 10 - 8, ', 0.6031227111816406), ('Replication sample ( n = 8,789).p', 'p-value: 6.0 × 10 - 4, 6.4 × 10 - 5, 3.1 × 10 - 11, 3.0 × 10 - 2, 8.0 × 10 - 7, ', 0.6468124985694885)]\n",
      "Effect Size: [('Multi-ethnic meta-analysis.Effect', 'Effect: - 0.95, 0.69, - 0.85, - 0.82, - 0.64, ', 0.45204293727874756), ('Multi-ethnic meta-analysis.SE', 'Standard Error of effect estimate: 0.15, 0.11, 0.14, 0.12, 0.09, ', 0.5280122756958008), ('Replication sample ( n = 8,789).Effect', 'effect: 0.63, 0.14, 0.12, 0.1, 0.09, ', 0.5168788433074951), ('Replication sample ( n = 8,789).SE', 'standard error of effect estimate: 0.18, 0.08 1.6, ', 0.5504616498947144)]\n",
      "Replication sample ( n = 8,789).N: [('Replication sample ( n = 8,789).N', None, 1)]\n",
      "\n",
      "nihms-1797266_table_8.csv\n",
      "SNP: [('APOE4 stratification.', 'APOE ε4 stratification: NO, APOE4 carriers, non- APOE4 carriers, ', 0.45007050037384033), ('SNP (rs).', 'single nucleotide polymorphism identifier (Reference Single nucleotide polymorphism): rs146729640, ', 0.4884442687034607)]\n",
      "Studies combined.: [('Studies combined.', 'Studies combined: Amish and NIA- LOAD, ', 1)]\n",
      "Number of observations.: [('Number of observations.', 'Number of observations: 4,872, 2,293, 2,579, ', 1)]\n",
      "Effect Size: [('Meta-Analysis results.Model', 'Meta-Analysis results: Fixed effect, Random effects, ', 0.41063129901885986), ('Meta-Analysis results.Hazard Ratio', 'Hazard Ratio: 2.07, 3.0, 1.5, 1.76, 3.56, ', 0.5157300233840942), ('Meta-Analysis results.Hazard Ratio 95%CI', 'hazard ratio 95%Confidence Interval: 1.54; 2.78, 0.72; 12.50, 1.072; 2.09, 0.86; 3.60, 2.19; 5.78, ', 0.4694945812225342)]\n",
      "P-value: [('Meta-Analysis results.P-value', 'P-value-value: <0.0001, 0.1308, 0.0178, 0.1219, 0.0831, ', 0.6912790536880493)]\n",
      "\n",
      "s13024-023-00633-4_table_2.csv\n",
      "Chr: [('Chr.', 'Chromosome number: 1, 2, 7, 8, 11, ', 0.6763195991516113)]\n",
      "Position: [('Position.', 'Position: 207573951, 127135234, 91069758, 30963282, 60173126, ', 0.48896729946136475)]\n",
      "SNP: [('Variant.', 'Variant: rs1752684, rs6733839, rs705353, rs117523305, rs7232, ', 0.6578899025917053)]\n",
      "RA: [('A1/A2 a (MAF).', 'effect allele / tested allele/other allele / non-effect allele a (Minor Allele Frequency): A/G (0.198), T/C (0.403), G/A (0.252), C/G (0.016), A/T (0.361), ', 0.7460706233978271)]\n",
      "Nearest Gene.: [('Nearest Gene.', 'Nearest Gene: CR1, BIN1, CYP27C1, CDK14, PURG TEX15, ', 1)]\n",
      "Cognitive Domain.: [('Cognitive Domain.', 'Cognitive Domain: Executive Function, Language, Memory, ', 1)]\n",
      "Cohorts b.: [('Cohorts b.', 'Cohorts b: All, Clinic, Community, Community All, ', 1)]\n",
      "Effect Size: [('Genetic effects.β G (SE)', 'Effect g (standard error of effect estimate): -0.028 (0.007), -0.042 (0.012), -0.020 (0.009), -0.026 (0.007), -0.054 (0.012), ', 0.5935451984405518), ('Genetic effects.β G × Age (SE)', 'Effect g × age (standard error of effect estimate): -0.002 (0.001), -0.001 (0.001), -0.004 (0.001), 0.000 (0.001), -0.005 (0.001), ', 0.455251008272171)]\n",
      "P-value: [('Genetic effects.P G', 'P-value g: 1.53 × 10 -4, 5.91 × 10 -4, 2.98 × 10 -2, 3.90 × 10 -4, 1.26 × 10 -5, ', 0.6706617474555969), ('Genetic effects.P G × Age', 'P-value g × age: 6.05 × 10 -3, 7.52 × 10 -2, 4.90 × 10 -2, 6.84 × 10 -2, 5.07 × 10 -2, ', 0.6131654381752014), ('Genetic effects.P Joint', 'P-value joint: 5.05 × 10 -5, 6.88 × 10 -4, 2.40 × 10 -2, 6.25 × 10 -4, 1.63 × 10 -5, ', 0.6872744560241699)]\n",
      "\n",
      "s13024-023-00633-4_table_3.csv\n",
      "Chr: [('Chr.', 'Chromosome number: 2, 4, 8, 9, 16, ', 0.6527140140533447)]\n",
      "Position: [('Position.', 'Position: 127135234, 179150192, 102060792, 10155013, 83947805, ', 0.4991665482521057)]\n",
      "SNP: [('Variant.', 'Variant: rs6733839, rs73005629, rs56162098, rs145989094, rs12447050, ', 0.6541425585746765), ('Individual locus.β G × Age (SE)', 'individual locus: -0.002 (0.001) -0.002 (0.001), -0.007 (0.002) -0.006 (0.002), 0.001 (0.001) -0.001 (0.001), -0.006 (0.002) -0.008 (0.003), -0.004 (0.003) -0.008 (0.003), ', 0.42733117938041687)]\n",
      "RA: [('A1/A2 a (MAF).', 'effect allele / tested allele/other allele / non-effect allele a (Minor Allele Frequency): T/C (0.403), C/T (0.022), C/T (0.138), A/T (0.013), C/T (0.400), ', 0.724932074546814)]\n",
      "Nearest Gene.: [('Nearest Gene.', 'Nearest Gene: BIN1 CYP27C1, LOC107984373, NCALD, PTPRD, OSGIN1 MLYCD, ', 1)]\n",
      "Cognitive Domain.: [('Cognitive Domain.', 'Cognitive Domain: Language Memory, Exec Function Memory, Language, Memory, ', 1)]\n",
      "Effect Size: [('Individual locus.β G (SE)', 'Effect g (standard error of effect estimate): -0.031 (0.006) -0.039 (0.006), -0.048 (0.019) -0.062 (0.021), 0.019 (0.008) -0.013 (0.009), -0.056 (0.026) -0.058 (0.028), -0.093 (0.025) -0.058 (0.028), ', 0.5734248161315918)]\n",
      "P-value: [('Individual locus.P G', 'P-value g: 6.90 × 10 -8 2.20 × 10 -9, 1.21 × 10 -2 3.97 × 10 -3, 1.64 × 10 -2 1.68 × 10 -1, 3.22 × 10 -2 4.56 × 10 -2, 3.40 × 10 -4 4.56 × 10 -2, ', 0.6728843450546265), ('Individual locus.P G × Age', 'P-value g × age: 3.62 × 10 -3 1.62 × 10 -3, 2.06 × 10 -4 8.12 × 10 -3, 1.84 × 10 -1 1.71 × 10 -1, 1.26 × 10 -2 3.14 × 10 -3, 9.29 × 10 -2 3.14 × 10 -3, ', 0.5825444459915161), ('Individual locus.P Joint', 'P-value joint: 2.70 × 10 -8 2.37 × 10 -9, 1.19 × 10 -4 2.11 × 10 -3, 3.08 × 10 -2 2.17 × 10 -1, 1.04 × 10 -2 5.92 × 10 -3, 8.84 × 10 -4 5.92 × 10 -3, ', 0.6739028096199036), ('Pleiotropy.P Placo,G', 'P-value placo,g: 2.72 × 10 -10, 3.69 × 10 -3, 5.85 × 10 -5, 2.70 × 10 -2, 1.22 × 10 -2, ', 0.555586040019989), ('Pleiotropy.P Placo,G × Age', 'P-value placo,g × age: 9.11 × 10 -4, 9.32 × 10 -4, 5.74 × 10 -3, 2.79 × 10 -3, 3.47 × 10 -2, ', 0.5390950441360474), ('Pleiotropy.P Placo, Joint', 'P-value placo, joint: 9.01 × 10 -12, 6.16 × 10 -5, 6.86 × 10 -6, 9.93 × 10 -4, 4.65 × 10 -3, ', 0.5947533249855042)]\n",
      "\n",
      "ACEL-22-e13938_table_4.csv\n",
      ": [('', ': 2-order interactions, 3- and 4-order interactions, B: APOE *4 + males, 3- order interaction, C: APOE *4 - males, ', 1)]\n",
      "SNP: [('Gene-gene combination', 'Gene-gene combination: rs3757949/rs7092522, rs62491484/rs35435718, rs62491484/rs28672744/ rs35435718, rs2686186/rs7092522/ rs12316064/ rs35511346, rs4674302/rs718630, ', 0.5972591638565063)]\n",
      "Genes included in the combination: [('Genes included in the combination', 'Genes included in the combination: GATA4 / IDE, NEIL2 / PGPEP1L, NEIL2 / TXNRD1 / PGPEP1L, FDFT1 / IDE / IGF1 / TXNRD1, AOX1 / PTPN1, ', 1)]\n",
      "Pathways involved: [('Pathways involved', 'Pathways involved: Stress response/ Metabolism, DNA repair/Stress response, Metabolism, DNA repair, DNA repair/ Metabolism, ', 1)]\n",
      "Effect Size: [('OR(95% CI.)', 'odds ratio(95% Confidence Interval: 1.42 (1.25, 1.62), 1.36 (1.19, 1.54), 1.56 (1.38, 1.76), 1.96 (1.72, 2.22), 1.46 (1.27, 1.69), ', 0.4121019244194031)]\n",
      "P-value: [('p -value (10,000 permutations).APOE *4 + females', 'P-value -value (10,000 permutations): 0.0001, 0.0002, 0.8127, 0.5017, 0.9976, ', 0.4632425010204315), ('p -value (10,000 permutations).APOE *4 + males', 'P-value -value (10,000 permutations): 0.1945, 0.6143, 0.8034, 0.9389, 0.0001, ', 0.4721827208995819), ('p -value (10,000 permutations).APOE *4 - females', 'P-value -value (10,000 permutations): 0.7051, 0.8744, 0.9658, 0.6944, 0.9709, ', 0.4665900468826294), ('p -value (10,000 permutations).APOE *4 - males', 'P-value -value (10,000 permutations): 0.6106, 0.0294, 0.4729, 0.824, 0.9489, ', 0.48043057322502136)]\n",
      "\n",
      "41591_2023_Article_2268_table_2.csv\n",
      "SNP: [('GWASmeta-analysis.SNP', 'Single nucleotide polymorphism identifier: rs6011998, rs13079464, rs2425884, rs10817108, rs2425881, ', 0.6490006446838379)]\n",
      "Chr: [('GWASmeta-analysis.chr:position', 'Chromosome number:position: 20:45269867, 3:13822439, 20:45258292, 9:113658671, 20:45255618, ', 0.6723979711532593)]\n",
      "RA: [('GWASmeta-analysis.EA/OA', 'effect allele/Other Allele: C/T, C/G, A/G, G/A, T/A, ', 0.596590518951416)]\n",
      "GWASmeta-analysis.Nearest gene(s): [('GWASmeta-analysis.Nearest gene(s)', None, 1)]\n",
      "Effect Size: [('i-Share(dichotomous).OR(95% CI)', 'odds ratio(95% Confidence Interval): 1.26 (0.83-1.92), 1.12 (0.91-1.40), 1.18 (0.95-1.45), 0.90 (0.69-1.17), 1.47 (1.03-2.01), ', 0.5026836395263672), ('i-Share (continuous).β(SE)', 'Effect(standard error of effect estimate): 0.164 (0.04), 0.014 (0.02), 0.077 (0.02), 0.058 (0.03), 0.063 (0.03), ', 0.6067800521850586), ('Nagahama(dichotomous).OR(95% CI)', 'odds ratio(95% Confidence Interval): 1.69 (1.33-2.13), 1.16 (0.97-1.40), 1.29 (1.09-1.52), 1.18 (0.98-1.43), 1.18 (1.01-1.37), ', 0.48577362298965454), ('Nagahama (continuous).β(SE)', 'Effect(standard error of effect estimate): 0.037 (0.008), 0.015 (0.006), 0.026 (0.005), 0.017 (0.006), 0.014 (0.005), ', 0.5862890481948853)]\n",
      "P-value: [('i-Share(dichotomous).P value', 'P-value value: 0.28, 0.29, 0.13, 0.44, 1.40×10 -02, ', 0.7504113912582397), ('i-Share (continuous).P value', 'P-value value: 4.20×10 -05, 0.50, 2.98×10 -04, 2.23×10 -02, 2.62×10 -02, ', 0.7592149972915649), ('Nagahama(dichotomous).P value', 'P-value value: 1.22×10 -05, 0.11, 3.48×10 -03, 0.07, 3.66×10 -02, ', 0.7511454820632935), ('Nagahama (continuous).P value', 'P-value value: 6.21×10 -07, 1.50×10 -02, 1.77×10 -06, 4.10×10 -03, 4.68×10 -03, ', 0.7479267716407776)]\n",
      "\n",
      "nihms-1797266_table_5.csv\n",
      "Chr: [('Chr', 'Chromosome number: 17, 9, 6, ', 0.6750221848487854)]\n",
      "SNP: [('Variant', 'Variant: 17:11183894_G_A, 9:128627091_C_G, 6:149756107_C_G, ', 0.4684421420097351), ('Variant (rs)', 'variant (Reference Single nucleotide polymorphism): rs146729640, rs534551495, rs145348074, ', 0.5827504396438599)]\n",
      "Data set: [('Data set', 'Data set: Amish, NIA-LOAD, ', 1)]\n",
      "# of subjects: [('# of subjects', 'Number of of subjects: 1520, 3350, ', 1)]\n",
      "AF: [('MAF', 'Minor Allele Frequency: 0.012, 0.038, 0.006, 0.024, 0.013, ', 0.6308693885803223)]\n",
      "Effect Size: [('Hazard ratio', 'Hazard ratio: 6.38, 1.49, 2.82, 0.98, 3.35, ', 0.5193595886230469)]\n",
      "P-value: [('P-value', 'P-value-value: 5.59e-09, 0.0217, 4.83e-08, 0.9356, 5.26e-08, ', 0.7559226751327515)]\n",
      "\n",
      "nihms-1797266_table_7.csv\n",
      "SNP: [('APOE4 stratification NIA-LOAD', 'APOE ε4 stratification nia-load: No, APOE4 carriers, non- APOE4 carriers, ', 0.43452638387680054), ('SNP (chr:pos)', 'Single nucleotide polymorphism identifier (chromosome number:position): 17:11183894_G_A, ', 0.5955944657325745), ('SNP (rs)', 'single nucleotide polymorphism identifier (Reference Single nucleotide polymorphism): rs146729640, ', 0.4884442687034607)]\n",
      "N (AD): [('N (AD)', 'Total sample size (ad): 1,785, 1,326, 459, ', 1)]\n",
      "N (controls): [('N (controls)', 'Total sample size (controls): 1,565, 572, 993, ', 1)]\n",
      "Effect Size: [('Hazard Ratio', 'Hazard Ratio: 1.49, 1.35, 1.82, ', 0.5352333188056946), ('Hazard Ratio 95% CI', 'hazard ratio 95% Confidence Interval: 1.06 ; 2.08, 0.95 ; 1.93, 0.96 ; 3.43, ', 0.4654291868209839)]\n",
      "P-value: [('P-value', 'P-value-value: 0.0217, 0.095, 0.0658, ', 0.7461717128753662)]\n",
      "Gene: [('Gene', 'Gene: SHISA6, ', 1)]\n",
      "\n",
      "41591_2023_Article_2268_table_1.csv\n",
      "Chr: [('Region', 'Region: 20q13.12, 3p25.1, 9q31.3, 3q21.2, 1q41, ', 0.5620454549789429), ('chr:position', 'Chromosome number:position: 20:45269867, 3:13822439, 20:45258292, 9:113658671, 20:45255618, ', 0.6723979711532593)]\n",
      "SNP: [('SNPALL', 'SNPALL: rs6011998, rs13079464, rs2425884, rs10817108, rs2425881, ', 0.6580638885498047), ('Function', 'Function: intronic, intergenic, UTR3, exonic, ', 0.44923117756843567)]\n",
      "RA: [('EA/OA', 'effect allele/Other Allele: C/T, C/G, A/G, G/A, T/A, ', 0.596590518951416)]\n",
      "AF: [('EAF', 'Effect Allele Frequency: 0.95, 0.46, 0.57, 0.21, 0.83, ', 0.6164336204528809)]\n",
      "Nearest gene(s): [('Nearest gene(s)', 'Nearest gene(s): SLC13A3, WNT7A, LPAR1, ITGB5 , UMPS, CENPF , KCNK2, ', 1)]\n",
      "Effect Size: [('Effect (β)', 'effect (Effect): 0.087, 0.026, 0.029, 0.033, 0.032, ', 0.5356195569038391), ('SE', 'Standard Error of effect estimate: 0.009, 0.004, 0.005, 0.012, 0.01, ', 0.5073163509368896)]\n",
      "Z - score: [('Z - score', 'Z-score statistic - score: 10.65, 8.7, 8.63, 8.2, 7.68, ', 1)]\n",
      "Dir: [('Dir', 'Dir: ++++, +-+-, +++?, +-+?, +???, ', 1)]\n",
      "N ext-PVS/ N total: [('N ext-PVS/ N total', 'n ext-pvs/ Total sample size total: 9,502/39,128, 9,614/39,822, 9,550/39,516, 9,496/39,087, 8,426/34,530, ', 1)]\n",
      "P-value: [('P valueEUR', 'P-value valueeur: 1.90×10 -24, 8.64×10 -17, 2.60×10 -18, 1.07×10 -15, 2.02×10 -15, ', 0.7449555993080139), ('P valueAll', 'P-value valueall: 1.80×10 -26, 3.41×10 -18, 6.02×10 -18, 2.46×10 -16, 1.59×10 -14, ', 0.7230997085571289), ('Het P value', 'Heterogeneity test p-value value: 0.11, 0.59, 0.14, 0.75, 0.06, ', 0.5893433094024658)]\n",
      "\n",
      "nihms-1797266_table_6.csv\n",
      "SNP: [('APOE4 stratification Amish', 'APOE ε4 stratification amish: No, APOE4 carriers, non- APOE4 carriers, ', 0.4554097354412079), ('SNP (chr:pos)', 'Single nucleotide polymorphism identifier (chromosome number:position): 17:11183894_G_A, ', 0.5955944657325745), ('SNP (rs)', 'single nucleotide polymorphism identifier (Reference Single nucleotide polymorphism): rs146729640, ', 0.4884442687034607)]\n",
      "N (CI): [('N (CI)', 'Total sample size (confidence interval): 362, 105, 257, ', 1)]\n",
      "N (CU): [('N (CU)', 'Total sample size (cu): 1,160, 290, 870, ', 1)]\n",
      "Effect Size: [('Hazard Ratio', 'Hazard Ratio: 6.38, 2.93, 8.96, ', 0.5116649866104126), ('Hazard Ratio 95% CI', 'hazard ratio 95% Confidence Interval: 3.42 ; 11.90, 1.16 ; 7.40, 4.25 ; 18.91, ', 0.4321613013744354)]\n",
      "P-value: [('P-value', 'P-value-value: 5.59e-09, 0.0232, 8.44e-09, ', 0.7551624178886414)]\n",
      "Gene: [('Gene', 'Gene: SHISA6, ', 1)]\n",
      "\n",
      "ACEL-22-e13938_table_3.csv\n",
      "SNP: [('Variant', 'Variant: rs13183641, rs4561, rs2348974, rs6556881, rs34886287, ', 0.6433566808700562), ('Gene SYMBOL', 'Gene SYMBOL: RHOBTB3, MSH3, FDFT1, RP11-\\xad 297N6.4, PAPPA, ', 0.4939909875392914)]\n",
      "Chr: [('Chr.', 'Chromosome number: 5, 8, 9, 10, 19, ', 0.6747028231620789)]\n",
      "Position: [('Position', 'Position: 95,147,287, 95,152,313, 95,143,394, 95,134,419, 80,077,309, ', 1)]\n",
      "RA: [('EA', 'Effect Allele: T, G, C, A, ', 0.6581827402114868)]\n",
      "Effect Size: [('OR', 'Odds Ratio: 0.873, 0.886, 1.119, 0.908, 1.11, ', 0.49570417404174805), ('OR_1', 'Odds Ratio_1: 0.909, 0.91, 1.093, 0.925, 1.105, ', 0.4880015254020691)]\n",
      "P-value: [('p', 'P-value: 0.003, 0.008, 0.015, 0.038, 0.029, ', 0.6428717374801636), ('p_1', 'P-value_1: 0.01, 0.011, 0.014, 0.034, 0.007, ', 0.7438564300537109)]\n",
      "\n",
      "nihms-1797266_table_3.csv\n",
      "Position: [('Location and base pair change (build hg19)', 'Location and base pair change (build hg19): 6:149756107_C_G, 9:128627091_C_G, 17:11183894_G_A, ', 0.6547622680664062), ('Overlapping Genes', 'Overlapping Genes: Intergenic variant. Closest gene: ZC3H12D, PBX3, SHISA6, ', 0.4438934922218323)]\n",
      "SNP: [('SNP (rs)', 'single nucleotide polymorphism identifier (Reference Single nucleotide polymorphism): rs145348074, rs534551495, rs146729640, ', 0.5564623475074768), ('Variant type', 'Variant type: Intergenic, Intron, ', 0.4564034044742584), ('Genes within +/- 500Kb', 'Genes within +/- 500Kb: UST, UST-AS1, LOC105378047, TAB2, TAB2-AS1, SUMO4, ZC3H12D, PPIL4, GINM1, KATNA1, LATS1, LOC645967, NUP43, PCMT1, LRP11, RAET1E-AS1, RAET1E, RAET1G, LOC105378052, GAPVD1, MAPKAP1, LOC51145, PBX3, LOC10192911, MVB12B, TMEM220-AS1, DNAH9, TMEM238L, PIRT, SHISA6,, ', 0.4667164087295532)]\n",
      "RA: [('MAF', 'Minor Allele Frequency: 0.0237382, 0.0379333, 0.0119911, ', 0.5966141223907471)]\n",
      "Effect Size: [('Hazard Ratio', 'Hazard Ratio: 3.35, 2.82, 6.38, ', 0.5270391702651978)]\n",
      "P-value: [('P-value', 'P-value-value: 5.26e-08, 4.83e-08, 5.59e-09, ', 0.7220847606658936)]\n",
      "\n",
      "Recent paper on AD GWAS (1)_table_1.csv\n",
      "SNP: [('Locus', 'Locus: VWA5B2, TRANK1, ', 0.41183096170425415), ('SNP', 'Single nucleotide polymorphism identifier: rs9837978, rs9867455, ', 0.6051782369613647)]\n",
      "Chr: [('Chromosome', 'Chromosome: 3, ', 0.7065351009368896)]\n",
      "Position: [('Position', 'Position: 183936947, 36953424, ', 0.5131635665893555)]\n",
      "RA: [('Effect allele', 'Effect allele: G, A, ', 0.7219093441963196), ('Reference allele', 'Reference allele: A, T, ', 0.5889571309089661), ('Mean effect allele frequency', 'Mean effect allele frequency: 0.287, 0.405, ', 0.6255719065666199)]\n",
      "P-value: [('P, MR-MEGA', 'P-value, mr-mega: 2.32E - 07, 7.33E - 08, ', 0.6305118203163147), ('P, ancestry heterogeneity', 'P-value, ancestry heterogeneity: 5.96E - 01, 1.18E - 01, ', 0.6734113693237305), ('P, random effects', 'P-value, random effects: 3.75E - 08, 3.49E - 08, ', 0.6263863444328308)]\n",
      "Effect Size: [('beta, random effects', 'Effect size (regression coefficient), random effects: - 0.053, - 0.042, ', 0.562483012676239), ('SE, random effects', 'Standard Error of effect estimate, random effects: 0.009, 0.008, ', 0.5276576280593872), ('I2', 'I-squared heterogeneity metric: 0.0, ', 0.46090176701545715)]\n",
      "AF: [('Minimum effect allele frequency', 'Minimum effect allele frequency: 0.171, 0.326, ', 0.6242307424545288), ('Maximum effect allele frequency', 'Maximum effect allele frequency: 0.45, 0.503, ', 0.6445790529251099)]\n",
      "\n",
      "Recent paper on AD GWAS (1)_table_2.csv\n",
      "SNP: [('Locus', 'Locus: BIN1, INPP5D, RHOH, CTSB, ECHDC3, ', 0.4055866599082947), ('SNP', 'Single nucleotide polymorphism identifier: rs6733839, rs10933431, rs2245466, rs1065712, rs7912495, ', 0.6305140852928162), ('Nsnps_in_credible_set', 'Number of Variants_in_credible_set: 1, 32, 2, ', 0.457278311252594)]\n",
      "Chr: [('Chromosome', 'Chromosome: 2, 4, 8, 10, 14, ', 0.6848959922790527)]\n",
      "Position: [('Position', 'Position: 127892810, 233981912, 40198846, 11702122, 11718713, ', 0.5232166051864624)]\n",
      "RA: [('Effect allele', 'Effect allele: T, C, A, ', 0.6809674501419067), ('Reference allele', 'Reference allele: C, G, ', 0.578101396560669)]\n",
      "Novel /uniFB01 ne- mapping: [('Novel /uniFB01 ne- mapping', 'Novel /uniFB01 ne- mapping: No, Yes, ', 1)]\n",
      "P-value: [('Posterior probability', 'Posterior probability: 1.0, 0.91, 0.965, ', 0.43237724900245667), ('P, MR-MEGA', 'P-value, mr-mega: 5.74E - 92, 1.63E - 16, 3.82E - 09, 6.42E - 09, 1.35E - 13, ', 0.6117171049118042), ('P, ancestry heterogeneity', 'P-value, ancestry heterogeneity: 3.13E - 01, 7.90E - 02, 9.31E - 01, 7.60E - 01, 6.02E - 01, ', 0.6520999670028687)]\n",
      "AF: [('chisq, ancestry (% total)', 'chisq, ancestry (% total): 14.27, 41.675, 0.128, 4.551, 48.894, ', 0.43565332889556885)]\n",
      "Effect Size: [('I2', 'I-squared heterogeneity metric: 58.01, 59.47, 49.16, 0.0, 57.45, ', 0.4712890386581421)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gwas_col_matching_engine = GWASColumnMatchingEngine(referencing_cols, use_llm = True, device = device)\n",
    "\n",
    "for file in os.listdir(\"./tables\"):\n",
    "    if \"table\" in file and \".csv\" in file and \"harmonized\" not in file:\n",
    "        print(file)\n",
    "        df = pd.read_csv(f\"./tables/{file}\")\n",
    "        df.columns = ['' if 'Unnamed:' in col else col for col in df.columns]\n",
    "        col_to_ref_col = gwas_col_matching_engine.match_many_col_to_ref_col(df)\n",
    "        for ref_col in col_to_ref_col:\n",
    "            print(f\"{ref_col}: {col_to_ref_col[ref_col]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012a639",
   "metadata": {},
   "source": [
    "Final formatting of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43a8ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# We now can try to use these dictionary to make a final dataset\n",
    "# need a list of columns that we sure that there might be multiple copies of it that we can melt them into many rows\n",
    "possible_ref_col_to_melt = [\"P-value\", \"Effect Size\", \"AF\"]\n",
    "gwas_col_matching_engine = GWASColumnMatchingEngine(referencing_cols)\n",
    "def format_original_table(df, remove_unique_col = False):\n",
    "    # map the columns\n",
    "    new_col_to_old_col_lst = gwas_col_matching_engine.match_many_col_to_ref_col(df)\n",
    "    df_with_ref_col = None \n",
    "    new_col_to_not_melt = [] # list of columns that are stable and not need to be melt\n",
    "    new_col_to_old_col_lst_to_melt = {}\n",
    "    for new_col in new_col_to_old_col_lst:\n",
    "        if len(new_col_to_old_col_lst[new_col]) == 1:\n",
    "            if (not remove_unique_col) or (remove_unique_col and new_col_to_old_col_lst[new_col][0][2] != 1):\n",
    "                if df_with_ref_col is None:\n",
    "                    df_with_ref_col = df[[new_col_to_old_col_lst[new_col][0][0]]]\n",
    "                    df_with_ref_col = df_with_ref_col.rename({new_col_to_old_col_lst[new_col][0][0]: new_col}, axis = 1)\n",
    "                else:\n",
    "                    df_with_ref_col[new_col] = df[new_col_to_old_col_lst[new_col][0][0]]\n",
    "                # add these single col to the list of not melt\n",
    "                new_col_to_not_melt.append(new_col)\n",
    "        else:\n",
    "            if new_col in possible_ref_col_to_melt:\n",
    "                old_col_lst = []\n",
    "                for col, _, _ in new_col_to_old_col_lst[new_col]:\n",
    "                    old_col_lst.append(col)\n",
    "                    if df_with_ref_col is None:\n",
    "                        df_with_ref_col = df[[col]]\n",
    "                    else:\n",
    "                        df_with_ref_col[col] = df[col]\n",
    "                new_col_to_old_col_lst_to_melt[new_col] = old_col_lst.copy()\n",
    "            else:\n",
    "                # make multiple copies with notes\n",
    "                for inx, (col, _, _) in enumerate(new_col_to_old_col_lst[new_col]):\n",
    "                    if df_with_ref_col is None:\n",
    "                        df_with_ref_col = df[[col]]\n",
    "                        df_with_ref_col = df_with_ref_col.rename({col: f\"{new_col}_{inx + 1}\"}, axis = 1)\n",
    "                    else:\n",
    "                        df_with_ref_col[f\"{new_col}_{inx + 1}\"] = df[col]\n",
    "                    df_with_ref_col[f\"{new_col}_{inx + 1} notes\"] = col\n",
    "                    # add these cols in group but not need to melt\n",
    "                    new_col_to_not_melt.append(f\"{new_col}_{inx + 1}\")\n",
    "                    new_col_to_not_melt.append(f\"{new_col}_{inx + 1} notes\")\n",
    "    # Melting stage\n",
    "    if len(new_col_to_old_col_lst_to_melt) > 0:\n",
    "        # now melting column in same groups\n",
    "        # Instead of keep melting, for each group, we make a new dataset of \n",
    "        # [stable col] + [to be melt col] => melt them as a new df\n",
    "        # do this for each gorup and then join together based on stable col\n",
    "        df_with_melt_col = None \n",
    "        for new_col in new_col_to_old_col_lst_to_melt:\n",
    "            temp_df = deepcopy(df_with_ref_col[new_col_to_not_melt + new_col_to_old_col_lst_to_melt[new_col]])\n",
    "            # create a temp row id for stable join\n",
    "            temp_df[\"_row_id\"] = np.arange(temp_df.shape[0])\n",
    "            temp_df = temp_df.melt(\n",
    "                id_vars = new_col_to_not_melt + [\"_row_id\"],    \n",
    "                value_vars = new_col_to_old_col_lst_to_melt[new_col], \n",
    "                var_name = f\"{new_col} notes\",      \n",
    "                value_name = f\"{new_col}\"\n",
    "            )\n",
    "            if df_with_melt_col is None:\n",
    "                df_with_melt_col = deepcopy(temp_df)\n",
    "            else:\n",
    "                df_with_melt_col = df_with_melt_col.merge(temp_df, how = \"inner\", on = [\"_row_id\"] + new_col_to_not_melt)\n",
    "        df_with_melt_col = df_with_melt_col.drop(\"_row_id\", axis = 1)\n",
    "        return df_with_melt_col\n",
    "    else:\n",
    "        return df_with_ref_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e26f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_df_all = None\n",
    "for file in os.listdir(\"./tables\"):\n",
    "    if \".csv\" in file and \"table\" in file and \"harmonized\" not in file:\n",
    "        df = pd.read_csv(f\"./tables/{file}\")\n",
    "        df.columns = ['' if 'Unnamed:' in col else col for col in df.columns]\n",
    "        modified_df = format_original_table(df, remove_unique_col = True)\n",
    "        modified_df[\"file_name\"] = file\n",
    "        if modified_df_all is None:\n",
    "            modified_df_all = modified_df.copy()\n",
    "        else:\n",
    "            modified_df_all = pd.concat([modified_df_all, modified_df], ignore_index = True)\n",
    "        modified_df.to_csv(f\"./harmonized_tables/{file.replace('.csv', '')}_harmonized.csv\", index = False)\n",
    "modified_df_all.to_csv(\"./harmonized_tables/harmonized_table.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
